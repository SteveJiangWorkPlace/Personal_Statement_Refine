import os
import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import time
from io import BytesIO
from PIL import Image

# ==========================================
# ğŸ”´ ç½‘ç»œä»£ç†é…ç½®
# è®¾ç½®HTTPå’ŒHTTPSä»£ç†ï¼Œç”¨äºç¡®ä¿åº”ç”¨èƒ½å¤Ÿé€šè¿‡ä»£ç†è®¿é—®Google Gemini API
# ==========================================
# os.environ["HTTP_PROXY"] = "http://127.0.0.1:7897"
# os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7897"

# ==========================================
# ä¾èµ–åº“æ£€æµ‹ä¸åˆå§‹åŒ–
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†å¤„ç†Wordæ–‡æ¡£å’ŒPDFæ–‡ä»¶çš„åº“ï¼Œå¹¶ç›¸åº”è®¾ç½®æ ‡å¿—
# ==========================================
HAS_DOCX = False
HAS_PDF = False

try:
    # å°è¯•å¯¼å…¥å¤„ç†Wordæ–‡æ¡£çš„åº“
    from docx import Document
    from docx.shared import Pt, Inches
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.enum.section import WD_SECTION
    HAS_DOCX = True
except ImportError:
    pass

try:
    # å°è¯•å¯¼å…¥å¤„ç†PDFæ–‡ä»¶çš„åº“
    import pypdf
    HAS_PDF = True
except ImportError:
    pass

# ==========================================
# è‡ªå®šä¹‰UIæ ·å¼å‡½æ•°
# é€šè¿‡æ³¨å…¥CSSæ¥åˆ›å»ºç±³è‰²èƒŒæ™¯å’Œå®è“è‰²æŒ‰é’®çš„è‡ªå®šä¹‰ç•Œé¢
# ==========================================
def apply_custom_css():
    st.markdown("""
    <style>
    /* å¼•å…¥ Inter å­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    
    /* å…¨å±€å˜é‡ - å®šåˆ¶é…è‰² */
    :root {
        --primary-color: #3666FA; /* å®è“ RGB 54, 102, 250 */
        --bg-color: #FBF7EC;      /* ç±³è‰² RGB 251, 247, 236 */
        --text-color: #3666FA;    /* å­—ä½“é¢œè‰²è·Ÿéšä¸»è‰² */
        --button-text: #FBF7EC;   /* æŒ‰é’®å†…æ–‡å­—é¢œè‰² (ç±³è‰²) */
    }

    /* åŸºç¡€é‡ç½® */
    html, body, [class*="css"] {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
        color: var(--text-color);
        background-color: var(--bg-color);
    }
    
    /* éšè— Streamlit é»˜è®¤ Header å’Œ Footer */
    header {visibility: hidden;}
    footer {visibility: hidden;}

    /* ä¸»å®¹å™¨èƒŒæ™¯ä¼˜åŒ– */
    .stApp {
        background-color: var(--bg-color);
    }

    /* ä¾§è¾¹æ ä¼˜åŒ– - æ·±è‰²æ²‰æµ¸å¼ */
    [data-testid="stSidebar"] {
        background-color: #0f172a; 
        border-right: 1px solid #1e293b;
    }
    
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3, 
    [data-testid="stSidebar"] label,
    [data-testid="stSidebar"] p,
    [data-testid="stSidebar"] .stMarkdown,
    [data-testid="stSidebar"] div {
        color: #e2e8f0 !important;
    }
    
    [data-testid="stSidebar"] hr {
        border-color: #334155 !important;
    }

    /* æ ‡é¢˜æ ·å¼ - å·¦å¯¹é½ï¼Œå¤§å­—ä½“ */
    h1 {
        color: var(--text-color) !important;
        font-weight: 800 !important;
        font-size: 2.5rem !important;
        letter-spacing: -0.02em;
        margin-bottom: 2rem !important;
        text-align: left !important;
    }
    
    /* å°æ ‡é¢˜æ ·å¼ */
    h2, h3 {
        color: var(--text-color) !important;
        font-weight: 600 !important;
        margin-top: 1rem !important;
        margin-bottom: 1rem !important;
    }
    
    /* æ™®é€šæ–‡æœ¬å’ŒLabelé¢œè‰² */
    p, label, .stMarkdown, .stText {
        color: var(--text-color) !important;
    }

    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] {
        border: none !important;
        border-radius: 8px !important;
        padding: 0.6rem 0.8rem !important;
        background-color: #ffffff !important;
        font-size: 0.95rem !important;
        color: #1e293b !important; /* è¾“å…¥æ¡†å†…éƒ¨æ–‡å­—æ·±è‰² */
        transition: all 0.2s ease;
    }

    .stTextInput input:focus, .stTextArea textarea:focus {
        border-color: var(--primary-color) !important;
        box-shadow: 0 0 0 2px rgba(54, 102, 250, 0.1) !important;
    }

    /* æŒ‰é’®ç¾åŒ– - å®è“èƒŒæ™¯ï¼Œç±³è‰²æ–‡å­— */
    .stButton button {
        background-color: var(--primary-color) !important;
        color: var(--button-text) !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
        font-size: 0.9rem !important;
        box-shadow: 0 1px 2px rgba(54, 102, 250, 0.2) !important;
        transition: all 0.2s ease !important;
        min-width: 100px !important;
        min-height: 38px !important;
        height: auto;
        line-height: 1.4;
    }
    
    /* å¼ºåˆ¶æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ é¢œè‰²ä¸ºç±³è‰² */
    .stButton button * {
        color: var(--button-text) !important;
    }

    .stButton button:hover {
        opacity: 0.9;
        transform: translateY(-1px);
    }
    
    /* ä¸‹è½½æŒ‰é’® */
    .stDownloadButton button {
        background-color: var(--primary-color) !important;
        color: #FFFFFF !important; /* ä¿®æ”¹ä¸ºç™½è‰²æ–‡å­— */
        border: none !important;
    }
                
    /* å¼ºåˆ¶ä¸‹è½½æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ é¢œè‰²ä¸€è‡´ */
    .stDownloadButton button * {
        color: #FFFFFF !important; /* ç¡®ä¿æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç™½è‰² */            
    }
                
    .stDownloadButton button:hover {
        opacity: 0.9;
    }

    /* Expander æ ·å¼å¾®è°ƒ - å¢åŠ å­—é‡ä»¥æ”¯æŒåŠ ç²—æ•ˆæœ */
    .streamlit-expanderHeader {
        background-color: #ffffff !important;
        border: 1px solid rgba(54, 102, 250, 0.2) !important;
        border-radius: 8px !important;
        color: var(--text-color) !important;
        font-weight: 600 !important; /* å¼ºåˆ¶åŠ ç²— */
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    [data-testid="stFileUploader"] {
        border: 1px dashed rgba(54, 102, 250, 0.4);
        background-color: #ffffff;
        border-radius: 8px;
        padding: 1rem;
        min-height: 150px; /* ç¡®ä¿ä¸æ–‡æœ¬æ¡†é«˜åº¦ä¸€è‡´ */
        display: flex;
        flex-direction: column;
        justify-content: center;
        width: 100% !important;
        box-sizing: border-box !important;
    }
    [data-testid="stFileUploader"]:hover {
        border-color: var(--primary-color);
        background-color: rgba(54, 102, 250, 0.05);
    }

    /* å¸ƒå±€é—´è·è°ƒæ•´ */
    .block-container {
        padding-top: 3rem !important;
        padding-bottom: 3rem !important;
        max-width: 1200px !important;
    }
    
    /* åˆ†å‰²çº¿é¢œè‰² */
    hr {
        border-color: rgba(54, 102, 250, 0.2) !important;
    }
    
    /* è¿›åº¦æ¡é¢œè‰² */
    .stProgress > div > div > div > div {
        background-color: var(--primary-color) !important;
    }
    
    /* æ·»åŠ é«˜äº®æ ·å¼ */
    .highlight {
        background-color: #FFEB3B;
        font-weight: bold;
    }
    
    /* ç»Ÿä¸€æ–‡æœ¬æ¡†æ ·å¼ */
    .stTextArea textarea {
        border: 1px solid rgba(54, 102, 250, 0.2) !important;
        border-radius: 8px !important;
        padding: 10px !important;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', sans-serif !important;
        font-size: 16px !important;
        line-height: 1.5 !important;
        color: #333333 !important;
        background-color: #ffffff !important;
        min-height: 300px !important;  /* æœ€å°é«˜åº¦ï¼Œå…è®¸æ‰©å±• */
        width: 100% !important;
        box-sizing: border-box !important;
    }
    
    /* é¢„è§ˆå®¹å™¨æ ·å¼ */
    .preview-container {
        border: 1px solid rgba(54, 102, 250, 0.2);
        border-radius: 8px;
        padding: 10px;
        background-color: #ffffff;
        height: 300px;
        overflow-y: auto;
        margin-top: 10px; /* ä¸æ–‡æœ¬åŒºåŸŸå¯¹é½ */
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', sans-serif;
        font-size: 16px;
        line-height: 1.5;
        color: #333;
    }
    
    /* æ‰¹æ³¨ç»“æœé¢„è§ˆå®¹å™¨ */
    .annotation-result-container {
        border: 1px solid rgba(54, 102, 250, 0.2);
        border-radius: 8px;
        padding: 10px;
        background-color: #ffffff;
        height: 300px;
        overflow-y: auto;
        margin-top: 10px;
        margin-bottom: 20px;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', sans-serif;
        font-size: 16px;
        line-height: 1.5;
        color: #333;
    }
    
    /* é¢„è§ˆæ ‡é¢˜æ ·å¼ */
    .preview-title {
        color: #3666FA;
        margin-bottom: 10px;
        font-weight: bold;
        font-size: 16px;
    }
    
    /* é¢„è§ˆæ–‡æœ¬æ ·å¼ */
    .preview-text {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', sans-serif;
        font-size: 16px;
        line-height: 1.5;
        color: #333;
    }
    
    /* ç»Ÿä¸€ä¿¡æ¯æ¡†æ ·å¼ */
    .stAlert {
        border-radius: 8px !important;
    }
    
    /* è°ƒæ•´åˆ—é—´è· */
    [data-testid="column"] {
        padding: 0 10px !important;
    }
    
    /* ç¡®ä¿é¢„è§ˆåŒºåŸŸä¸æ–‡æœ¬æ¡†å¯¹é½ */
    .preview-wrapper {
        height: 100%;
        display: flex;
        flex-direction: column;
    }
    
    /* ä¿®æ”¹éƒ¨åˆ†é«˜äº®æ˜¾ç¤º */
    .modified-text {
        background-color: #FFEB3B;
        font-weight: bold;
    }
    
    /* ç¡®ä¿ä¸Šä¼ æ–‡ä»¶åŒºåŸŸå’Œæ–‡æœ¬æ¡†é¡¶ç«¯å¯¹é½ */
    .top-align-container {
        display: flex;
        align-items: flex-start;
    }
    
    /* ç§»é™¤ä¸Šä¼ æ–‡ä»¶åŒºåŸŸçš„ä¸Šè¾¹è· */
    .top-align-container [data-testid="stFileUploader"] {
        margin-top: 0 !important;
    }
    
    /* ç§»é™¤æ–‡æœ¬åŒºåŸŸçš„ä¸Šè¾¹è· */
    .top-align-container .stTextArea {
        margin-top: 0 !important;
    }

    /* æµå¼æ˜¾ç¤ºå…‰æ ‡æ•ˆæœ */
    .streaming-cursor::after {
        content: "â–Œ";
        animation: blink 1s infinite;
        color: var(--primary-color);
    }
    @keyframes blink {
        0%, 50% { opacity: 1; }
        51%, 100% { opacity: 0; }
    }

    /* ç»Ÿä¸€æŒ‰é’®æ ·å¼ */
    .uniform-button button {
        min-width: 100px !important;
        min-height: 38px !important;
        width: 100% !important;
        box-sizing: border-box !important;
        white-space: nowrap !important;
        overflow: hidden !important;
        text-overflow: ellipsis !important;
    }

    /* ç¡®è®¤å†…å®¹æŒ‰é’®ç‰¹æ®Šæ ·å¼ */
    button[data-testid*="confirm_p_"] {
        background-color: white !important;
        color: #3666FA !important;
        border: 2px solid #3666FA !important;
    }

    button[data-testid*="confirm_p_"]:hover {
        opacity: 0.8;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# é¡µé¢é…ç½®ä¸ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
# è®¾ç½®é¡µé¢æ ‡é¢˜ã€å¸ƒå±€å’Œåˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ä¼šè¯çŠ¶æ€å˜é‡
# ==========================================
st.set_page_config(page_title="ä¸ªäººé™ˆè¿°ä¿®æ”¹", layout="wide")

# åº”ç”¨è‡ªå®šä¹‰UIæ ·å¼
apply_custom_css()

# è°ƒè¯•æ¨¡å¼æ ‡å¿—
DEBUG_MODE = True

# æ—¥å¿—ç³»ç»Ÿ
import logging
from datetime import datetime

def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger('psr_debug')
    logger.setLevel(logging.DEBUG)

    # é¿å…é‡å¤æ·»åŠ handler
    if not logger.handlers:
        # æ–‡ä»¶handler
        fh = logging.FileHandler('psr_debug.log', encoding='utf-8')
        fh.setLevel(logging.DEBUG)

        # æ§åˆ¶å°handlerï¼ˆä»…å½“DEBUG_MODEå¼€å¯æ—¶ï¼‰
        if DEBUG_MODE:
            ch = logging.StreamHandler()
            ch.setLevel(logging.DEBUG)

        # æ ¼å¼åŒ–
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        fh.setFormatter(formatter)
        if DEBUG_MODE:
            ch.setFormatter(formatter)

        logger.addHandler(fh)
        if DEBUG_MODE:
            logger.addHandler(ch)

    return logger

logger = setup_logging()

def log_session_state_summary():
    """è®°å½•session stateçš„æ‘˜è¦ä¿¡æ¯"""
    logger.info("=== Session State æ‘˜è¦ ===")
    logger.info(f"sections_dataé•¿åº¦: {len(st.session_state.get('sections_data', []))}")
    logger.info(f"confirmed_paragraphs: {st.session_state.get('confirmed_paragraphs', set())}")
    logger.info(f"confirmed_contents keys: {list(st.session_state.get('confirmed_contents', {}).keys())}")

    # æ£€æŸ¥confirmed_contentsä¸­çš„å®é™…å†…å®¹
    confirmed_contents = st.session_state.get('confirmed_contents', {})
    for idx, content in confirmed_contents.items():
        logger.info(f"confirmed_contents[{idx}] é•¿åº¦: {len(content) if content else 0}")
        if content and len(content) < 100:
            logger.debug(f"confirmed_contents[{idx}] å†…å®¹: {content}")

    logger.info(f"final_preview_texté•¿åº¦: {len(st.session_state.get('final_preview_text', ''))}")
    logger.info(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
    logger.info(f"generation_complete: {st.session_state.get('generation_complete', False)}")
    logger.info(f"show_sections: {st.session_state.get('show_sections', False)}")
    logger.info("=== Session State æ‘˜è¦ç»“æŸ ===")

# åœ¨è„šæœ¬å¼€å§‹æ—¶è®°å½•session state
log_session_state_summary()

# åˆå§‹åŒ–æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡ï¼Œç”¨äºåœ¨é¡µé¢é‡æ–°åŠ è½½æ—¶ä¿æŒæ•°æ®
if 'ps_content' not in st.session_state: st.session_state['ps_content'] = ""  # åŸå§‹PSå†…å®¹
if 'curr_content' not in st.session_state: st.session_state['curr_content'] = ""  # è¯¾ç¨‹å†…å®¹
if 'strategy_content' not in st.session_state: st.session_state['strategy_content'] = ""  # ç­–ç•¥å†…å®¹
if 'sections_data' not in st.session_state: st.session_state['sections_data'] = []  # æ®µè½æ•°æ®
if 'translation_results' not in st.session_state: st.session_state['translation_results'] = {}  # ç¿»è¯‘ç»“æœ
if 'edited_translations' not in st.session_state: st.session_state['edited_translations'] = {}  # ç¼–è¾‘åçš„ç¿»è¯‘
if 'refine_results' not in st.session_state: st.session_state['refine_results'] = {}  # ä¿®æ”¹ç»“æœ
if 'preview_results' not in st.session_state: st.session_state['preview_results'] = {}  # é¢„è§ˆç»“æœ
if 'generation_complete' not in st.session_state: st.session_state['generation_complete'] = False  # ç”Ÿæˆå®Œæˆæ ‡å¿—
if 'full_response' not in st.session_state: st.session_state['full_response'] = ""  # å®Œæ•´å“åº”
if 'show_sections' not in st.session_state: st.session_state['show_sections'] = False  # æ˜¾ç¤ºæ®µè½æ ‡å¿—
if 'annotation_processing' not in st.session_state: st.session_state['annotation_processing'] = {}  # æ‰¹æ³¨å¤„ç†çŠ¶æ€
if 'annotation_results' not in st.session_state: st.session_state['annotation_results'] = {}  # æ‰¹æ³¨å¤„ç†ç»“æœ
if 'original_texts' not in st.session_state: st.session_state['original_texts'] = {}  # åŸå§‹æ–‡æœ¬ï¼Œç”¨äºæ¯”è¾ƒ
if 'final_preview_text' not in st.session_state: st.session_state['final_preview_text'] = ""  # æœ€ç»ˆé¢„è§ˆæ–‡æœ¬
if 'final_preview_text_cleaned' not in st.session_state: st.session_state['final_preview_text_cleaned'] = ""  # æ¸…ç†åçš„æœ€ç»ˆé¢„è§ˆæ–‡æœ¬
if 'confirmed_paragraphs' not in st.session_state: st.session_state['confirmed_paragraphs'] = set()  # å·²ç¡®è®¤æ®µè½çš„ç´¢å¼•
if 'confirmed_contents' not in st.session_state: st.session_state['confirmed_contents'] = {}  # å·²ç¡®è®¤æ®µè½çš„å†…å®¹

# ä»Streamlit secretsè·å–Google API Key
api_key = st.secrets.get("GOOGLE_API_KEY")
if api_key:
    os.environ["GOOGLE_API_KEY"] = api_key
    genai.configure(api_key=api_key)
else:
    pass  # é”™è¯¯ä¿¡æ¯åœ¨ä¾§è¾¹æ ä¸­æ˜¾ç¤º

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.markdown("### è®¾ç½®")
    if api_key:
        st.success("âœ… API Key å·²ä» Secrets åŠ è½½")
    else:
        st.sidebar.error("âŒ API Key æœªé…ç½®")
    st.divider()
    # æ˜¾ç¤ºå·²ç”Ÿæˆæ®µè½çš„æ•°é‡
    if st.session_state['sections_data']:
        st.success(f"å½“å‰å·²ç”Ÿæˆ {len(st.session_state['sections_data'])} ä¸ªæ®µè½")

    st.divider()
    st.markdown("### è¯Šæ–­ä¿¡æ¯")

    # æ˜¾ç¤ºæœ€ç»ˆé¢„è§ˆçŠ¶æ€
    if st.session_state['final_preview_text']:
        st.info(f"æœ€ç»ˆé¢„è§ˆæ–‡æœ¬é•¿åº¦: {len(st.session_state['final_preview_text'])} å­—ç¬¦")
        # æ˜¾ç¤ºå‰100å­—ç¬¦é¢„è§ˆ
        preview_text = st.session_state['final_preview_text']
        if len(preview_text) > 100:
            st.text_area("final_preview_texté¢„è§ˆ", value=preview_text[:500], height=150, key="sidebar_preview", disabled=True)
        else:
            st.text_area("final_preview_texté¢„è§ˆ", value=preview_text, height=150, key="sidebar_preview", disabled=True)

        if st.session_state.get('final_preview_text_cleaned'):
            st.info(f"æ¸…ç†ç‰ˆæœ¬é•¿åº¦: {len(st.session_state['final_preview_text_cleaned'])} å­—ç¬¦")
            cleaned_preview = st.session_state['final_preview_text_cleaned']
            if len(cleaned_preview) > 100:
                st.text_area("final_preview_text_cleanedé¢„è§ˆ", value=cleaned_preview[:500], height=150, key="sidebar_cleaned_preview", disabled=True)
            else:
                st.text_area("final_preview_text_cleanedé¢„è§ˆ", value=cleaned_preview, height=150, key="sidebar_cleaned_preview", disabled=True)
    else:
        st.warning("æœ€ç»ˆé¢„è§ˆæ–‡æœ¬ä¸ºç©º")

    # æ˜¾ç¤ºå·²ç¡®è®¤æ®µè½çŠ¶æ€
    confirmed_count = len(st.session_state['confirmed_paragraphs'])
    total_paragraphs = len(st.session_state['sections_data'])
    if total_paragraphs > 0:
        st.info(f"å·²ç¡®è®¤æ®µè½: {confirmed_count}/{total_paragraphs}")
        if confirmed_count > 0:
            confirmed_indices = sorted(list(st.session_state['confirmed_paragraphs']))
            st.info(f"å·²ç¡®è®¤æ®µè½ç´¢å¼•: {confirmed_indices}")

    # æ£€æŸ¥confirmed_contents
    if st.session_state['confirmed_contents']:
        st.info(f"confirmed_contentsä¸­æœ‰ {len(st.session_state['confirmed_contents'])} ä¸ªæ®µè½")
        for idx, content in st.session_state['confirmed_contents'].items():
            content_len = len(content) if content else 0
            st.info(f"æ®µè½ {idx}: {content_len} å­—ç¬¦")
    else:
        st.warning("confirmed_contentsä¸ºç©º")

    # è¯Šæ–­æŒ‰é’®
    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“‹ è¾“å‡ºè¯¦ç»†è¯Šæ–­æ—¥å¿—", key="diagnostic_btn"):
            logger.info(f"=== è¯¦ç»†è¯Šæ–­æ—¥å¿— ===")
            logger.info(f"final_preview_texté•¿åº¦: {len(st.session_state['final_preview_text'])}")
            logger.info(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
            logger.info(f"final_preview_text_display session stateå­˜åœ¨: {'final_preview_text_display' in st.session_state}")
            logger.info(f"sections_dataé•¿åº¦: {len(st.session_state['sections_data'])}")
            logger.info(f"confirmed_paragraphs: {st.session_state['confirmed_paragraphs']}")
            logger.info(f"confirmed_contents keys: {list(st.session_state['confirmed_contents'].keys())}")

            # æ£€æŸ¥æ¯ä¸ªconfirmed_contentsçš„å†…å®¹
            for idx, content in st.session_state['confirmed_contents'].items():
                logger.info(f"confirmed_contents[{idx}]é•¿åº¦: {len(content) if content else 0}")
                if content and len(content) < 500:
                    logger.info(f"confirmed_contents[{idx}]å†…å®¹å‰200å­—ç¬¦: {content[:200]}")

            # æ£€æŸ¥final_preview_text_display
            if 'final_preview_text_display' in st.session_state:
                display_val = st.session_state['final_preview_text_display']
                logger.info(f"final_preview_text_displayé•¿åº¦: {len(display_val) if display_val else 0}")
                if display_val and len(display_val) < 500:
                    logger.info(f"final_preview_text_displayå‰200å­—ç¬¦: {display_val[:200]}")

            # æ£€æŸ¥display_textçš„è®¡ç®—
            cleaned_text = st.session_state.get('final_preview_text_cleaned', '')
            if cleaned_text and cleaned_text.strip():
                display_text = cleaned_text
                logger.info(f"display_textä½¿ç”¨final_preview_text_cleanedï¼Œé•¿åº¦: {len(display_text)}")
            else:
                display_text = st.session_state['final_preview_text']
                logger.info(f"display_textä½¿ç”¨final_preview_textï¼Œé•¿åº¦: {len(display_text)}")
            logger.info(f"display_textå‰200å­—ç¬¦: {display_text[:200] if display_text else 'ç©º'}")

            logger.info(f"=== è¯Šæ–­æ—¥å¿—ç»“æŸ ===")
            st.success("è¯¦ç»†è¯Šæ–­æ—¥å¿—å·²è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶")

    with col2:
        if st.button("ğŸ”„ å¼ºåˆ¶é‡å»ºé¢„è§ˆ", key="rebuild_preview_btn"):
            logger.info(f"=== å¼ºåˆ¶é‡å»ºé¢„è§ˆ ===")
            rebuilt_text = rebuild_final_preview()
            logger.info(f"é‡å»ºç»“æœé•¿åº¦: {len(rebuilt_text)}")
            if rebuilt_text and rebuilt_text.strip():
                st.session_state['final_preview_text'] = rebuilt_text
                logger.info(f"final_preview_textå·²æ›´æ–°ï¼Œé•¿åº¦: {len(rebuilt_text)}")
                st.success(f"é¢„è§ˆå·²é‡å»ºï¼Œé•¿åº¦: {len(rebuilt_text)} å­—ç¬¦")
                # æ¸…é™¤æ¸…ç†ç‰ˆæœ¬
                st.session_state['final_preview_text_cleaned'] = ''
                logger.info("å·²æ¸…é™¤final_preview_text_cleaned")
                st.rerun()
            else:
                logger.warning(f"é‡å»ºç»“æœä¸ºç©º")
                st.error("é‡å»ºå¤±è´¥ï¼Œç»“æœä¸ºç©º")

# è®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹
model_name = "gemini-2.5-pro"

# å®‰å…¨è®¾ç½®ï¼Œç”¨äºäº¤äº’å¼APIè°ƒç”¨
safety_settings_interactive = {
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# ==========================================
# å·¥å…·å‡½æ•°
# åŒ…å«å„ç§è¾…åŠ©åŠŸèƒ½ï¼Œå¦‚æ–‡ä»¶å¤„ç†ã€æ–‡æœ¬æ¸…ç†å’Œæ ¼å¼è½¬æ¢
# ==========================================

# ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
def extract_text_from_file(uploaded_file):
    """ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬ï¼Œæ”¯æŒDOCXã€PDFå’ŒTXTæ ¼å¼"""
    if not uploaded_file: return ""
    file_type = uploaded_file.name.split('.')[-1].lower()
    text = ""
    try:
        if file_type == 'docx' and HAS_DOCX:
            doc = Document(uploaded_file)
            for para in doc.paragraphs: text += para.text + "\n"
        elif file_type == 'pdf' and HAS_PDF:
            reader = pypdf.PdfReader(uploaded_file)
            for page in reader.pages: text += page.extract_text() + "\n"
        elif file_type == 'txt':
            text = uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        return f"[è¯»å–æ–‡ä»¶å‡ºé”™: {e}]"
    return text

# æ¸…é™¤æ–‡æœ¬ä¸­çš„æ˜Ÿå·
def clean_asterisks(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„æ‰€æœ‰æ˜Ÿå·å­—ç¬¦"""
    if not text: return ""
    return text.replace("*", "")

# ç§»é™¤MarkdownåŠ ç²—æ ‡è®°
def remove_markdown_bold(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„MarkdownåŠ ç²—æ ‡è®°ï¼ˆ**ï¼‰"""
    return text.replace("**", "")

# è¿‡æ»¤AIç”Ÿæˆå†…å®¹ä¸­çš„é—®å€™è¯­
def filter_ai_greeting(text):
    """ç§»é™¤AIç”Ÿæˆå†…å®¹å¼€å¤´çš„å¸¸è§é—®å€™è¯­å’Œä»‹ç»è¯­"""
    greeting_patterns = [
        r'^å¥½çš„ï¼Œä½œä¸º.*?é¡¾é—®.*?\n+',
        r'^ä½œä¸º.*?é¡¾é—®.*?\n+',
        r'^æˆ‘å°†.*?åˆ†æ.*?\n+',
        r'^ä¸‹é¢æˆ‘å°†.*?\n+',
        r'^æˆ‘ä¼š.*?å¸®åŠ©æ‚¨.*?\n+',
        r'^è®©æˆ‘.*?ä¸ºæ‚¨.*?\n+'
    ]
    
    for pattern in greeting_patterns:
        text = re.sub(pattern, '', text, flags=re.DOTALL)
    
    return text

# åˆ›å»ºå¸¦æœ‰æ ¼å¼çš„Wordæ–‡æ¡£
def create_docx_smart(text_content, major_name=""):
    """åˆ›å»ºæ ¼å¼åŒ–çš„Wordæ–‡æ¡£ï¼ŒåŒ…æ‹¬é¡µçœ‰ã€å­—ä½“è®¾ç½®å’ŒåŠ ç²—é«˜äº®"""
    if not HAS_DOCX: return None
    doc = Document()
    
    # è®¾ç½®é¡µé¢è¾¹è·
    sections = doc.sections
    for section in sections:
        section.top_margin = Inches(1)
        section.bottom_margin = Inches(1)
        section.left_margin = Inches(1)
        section.right_margin = Inches(1)
    
    # æ·»åŠ é¡µçœ‰
    header_text = f"Personal Statement - {major_name}" if major_name else "Personal Statement"
    header = doc.sections[0].header
    header_para = header.paragraphs[0]
    header_para.text = header_text
    header_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # è®¾ç½®é¡µçœ‰æ–‡æœ¬æ ¼å¼
    header_run = header_para.runs[0]
    header_run.font.name = 'Arial'
    header_run.font.size = Pt(11)

    # è®¾ç½®æ­£æ–‡é»˜è®¤æ ·å¼
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Arial'
    font.size = Pt(11)
    
    # å¤„ç†æ­£æ–‡å†…å®¹ï¼Œä¿ç•™åŠ ç²—æ ¼å¼
    lines = text_content.split('\n')
    for line in lines:
        if not line.strip(): continue
        clean_line = line.replace('[[LOGIC]]', '').replace('[[DRAFT]]', '')
        p = doc.add_paragraph()
        parts = re.split(r'(\*\*.*?\*\*)', clean_line)
        for part in parts:
            if part.startswith('**') and part.endswith('**'):
                clean_text = part[2:-2]
                run = p.add_run(clean_text)
                run.bold = True
            else:
                p.add_run(part)
    
    # å°†æ–‡æ¡£ä¿å­˜åˆ°å†…å­˜ç¼“å†²åŒº
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ç”ŸæˆHTMLé¢„è§ˆï¼Œé«˜äº®æ˜¾ç¤ºåŠ ç²—éƒ¨åˆ†
def generate_preview_html(text_with_markdown):
    """å°†Markdownæ ¼å¼çš„æ–‡æœ¬è½¬æ¢ä¸ºHTMLé¢„è§ˆï¼Œé«˜äº®æ˜¾ç¤ºåŠ ç²—éƒ¨åˆ†"""
    # æ›¿æ¢markdownåŠ ç²—è¯­æ³•ä¸ºHTML spanæ ‡ç­¾
    html_text = re.sub(r'\*\*(.*?)\*\*', r'<span style="background-color: #FFEB3B; font-weight: bold;">\1</span>', text_with_markdown)
    
    # æ·»åŠ HTMLæ ·å¼ï¼Œç¡®ä¿ä¸æ–‡æœ¬æ¡†æ ·å¼ä¸€è‡´
    styled_html = f"""
    <div class="preview-container">
        <div class="preview-text">
            {html_text}
        </div>
    </div>
    """
    return styled_html

# æ–°å¢å‡½æ•°ï¼šæ¯”è¾ƒæ–‡æœ¬å¹¶é«˜äº®å·®å¼‚éƒ¨åˆ†
def highlight_differences(original_text, new_text):
    """æ¯”è¾ƒåŸå§‹æ–‡æœ¬å’Œæ–°æ–‡æœ¬ï¼Œé«˜äº®æ˜¾ç¤ºå·®å¼‚éƒ¨åˆ†"""
    # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…ä¸Šéœ€è¦æ›´å¤æ‚çš„æ–‡æœ¬å·®å¼‚æ¯”è¾ƒç®—æ³•
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼šå°†æ–°æ–‡æœ¬ä¸­çš„æ¯ä¸ªå¥å­ä¸åŸæ–‡æœ¬æ¯”è¾ƒ
    
    # å¦‚æœåŸæ–‡æœ¬ä¸ºç©ºï¼Œåˆ™å°†æ•´ä¸ªæ–°æ–‡æœ¬é«˜äº®æ˜¾ç¤º
    if not original_text:
        return f"<span class='modified-text'>{new_text}</span>"
    
    # å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­
    def split_into_sentences(text):
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å¥å­ï¼Œè€ƒè™‘å„ç§æ ‡ç‚¹ç¬¦å·
        return re.split(r'([.!?ã€‚ï¼ï¼Ÿ\n]+)', text)
    
    orig_sentences = split_into_sentences(original_text)
    new_sentences = split_into_sentences(new_text)
    
    # åˆå¹¶ç›¸é‚»çš„åˆ†å‰²ç»“æœ
    orig_sentences_merged = []
    for i in range(0, len(orig_sentences)-1, 2):
        if i+1 < len(orig_sentences):
            orig_sentences_merged.append(orig_sentences[i] + orig_sentences[i+1])
        else:
            orig_sentences_merged.append(orig_sentences[i])
    
    new_sentences_merged = []
    for i in range(0, len(new_sentences)-1, 2):
        if i+1 < len(new_sentences):
            new_sentences_merged.append(new_sentences[i] + new_sentences[i+1])
        else:
            new_sentences_merged.append(new_sentences[i])
    
    # æ ‡è®°æ¯ä¸ªæ–°å¥å­æ˜¯å¦å­˜åœ¨äºåŸæ–‡æœ¬ä¸­
    result = []
    for sentence in new_sentences_merged:
        if sentence.strip() and sentence.strip() not in original_text:
            result.append(f"<span class='modified-text'>{sentence}</span>")
        else:
            result.append(sentence)
    
    # åˆå¹¶ç»“æœ
    return "".join(result)

# æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡
def contains_chinese(text):
    """æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    for char in text:
        if '\u4e00' <= char <= '\u9fff':
            return True
    return False

# æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
def contains_annotation(text):
    """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨æ ‡è®°"""
    return ('ã€' in text and 'ã€‘' in text) or ('[' in text and ']' in text)

# ä»AIä¿®æ”¹æ€è·¯ä¸­æå–æ®µè½ä¸»é¢˜
def extract_paragraph_topic(logic_text):
    """ä»AIä¿®æ”¹æ€è·¯ä¸­æå–æ®µè½ä¸»é¢˜"""
    if not logic_text:
        return "æœªè¯†åˆ«"

    # å°è¯•ä»å¸¸è§æ¨¡å¼ä¸­æå–
    patterns = [
        r"æœ¬æ®µåŠŸèƒ½è¯†åˆ«ï¼š\[(.+?)\]",
        r"åŠŸèƒ½ï¼š(.+?)(?:\n|$)",
        r"ä¸»é¢˜ï¼š(.+?)(?:\n|$)"
    ]

    for pattern in patterns:
        match = re.search(pattern, logic_text)
        if match:
            return match.group(1).strip()

    # æ ¹æ®å…³é”®è¯æ¨æ–­
    keywords = {
        "åŠ¨æœº": ["åŠ¨æœº", "å…´è¶£", "inspiration", "motivation"],
        "å­¦æœ¯èƒŒæ™¯": ["å­¦æœ¯", "å­¦ä¹ ", "è¯¾ç¨‹", "academic"],
        "ç ”ç©¶ç»å†": ["ç ”ç©¶", "é¡¹ç›®", "å®éªŒ", "research"],
        "å·¥ä½œç»å†": ["å·¥ä½œ", "å®ä¹ ", "èŒä¸š", "work"],
        "èŒä¸šè§„åˆ’": ["è§„åˆ’", "ç›®æ ‡", "æœªæ¥", "career"],
        "æ‹©æ ¡ç†ç”±": ["å­¦æ ¡", "è¯¾ç¨‹", "ä¸“ä¸š", "why school"]
    }

    for topic, key_list in keywords.items():
        if any(key in logic_text.lower() for key in key_list):
            return topic

    return "æ®µè½å†…å®¹"

# é‡å»ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬
def rebuild_final_preview():
    """æŒ‰æ®µè½é¡ºåºé‡å»ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬"""
    logger.info(f"=== å¼€å§‹é‡å»ºæœ€ç»ˆé¢„è§ˆ ===")
    logger.info(f"sections_dataé•¿åº¦: {len(st.session_state.get('sections_data', []))}")
    logger.info(f"confirmed_paragraphs: {st.session_state.get('confirmed_paragraphs', set())}")
    logger.info(f"confirmed_contents keys: {list(st.session_state.get('confirmed_contents', {}).keys())}")

    if not st.session_state['sections_data']:
        logger.warning("æ²¡æœ‰æ®µè½æ•°æ®")
        if DEBUG_MODE:
            st.warning("æ²¡æœ‰æ®µè½æ•°æ®")  # è°ƒè¯•ä¿¡æ¯
        return ""

    # ç¡®ä¿confirmed_paragraphsæ˜¯listç±»å‹
    if isinstance(st.session_state['confirmed_paragraphs'], set):
        confirmed_indices = sorted(list(st.session_state['confirmed_paragraphs']))
    else:
        confirmed_indices = sorted(st.session_state['confirmed_paragraphs'])

    logger.info(f"confirmed_indices: {confirmed_indices}")

    if not confirmed_indices:
        logger.warning(f"å·²ç¡®è®¤æ®µè½ä¸ºç©º: {st.session_state['confirmed_paragraphs']}")
        if DEBUG_MODE:
            st.warning(f"å·²ç¡®è®¤æ®µè½ä¸ºç©º: {st.session_state['confirmed_paragraphs']}")  # è°ƒè¯•ä¿¡æ¯
        return ""

    paragraphs = []
    for idx in confirmed_indices:
        if idx < len(st.session_state['sections_data']):
            # è°ƒè¯•è¾“å‡º
            has_content = idx in st.session_state['confirmed_contents']
            logger.info(f"å¤„ç†æ®µè½ {idx}, confirmed_contentsä¸­æœ‰: {has_content}")

            if DEBUG_MODE:
                st.info(f"å¤„ç†æ®µè½ {idx}, confirmed_contentsä¸­æœ‰: {has_content}")

            if idx in st.session_state['confirmed_contents']:
                current_text = st.session_state['confirmed_contents'][idx]
                logger.info(f"æ®µè½ {idx} ä»confirmed_contentsè·å–å†…å®¹ï¼Œé•¿åº¦: {len(current_text) if current_text else 0}")
                logger.debug(f"æ®µè½ {idx} å†…å®¹å‰100å­—ç¬¦: {current_text[:100] if current_text else 'ç©º'}")

                # å¦‚æœconfirmed_contentsä¸­çš„å†…å®¹ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹è·å–
                if not current_text or not current_text.strip():
                    logger.warning(f"æ®µè½ {idx} confirmed_contentsä¸­çš„å†…å®¹ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹è·å–")
                    textarea_key = f"draft_p_{idx}"
                    if textarea_key in st.session_state:
                        fallback_text = st.session_state[textarea_key]
                        if fallback_text and fallback_text.strip():
                            current_text = fallback_text
                            logger.info(f"æ®µè½ {idx} ä»textareaè·å–æ›¿ä»£å†…å®¹ï¼Œé•¿åº¦: {len(current_text)}")
                    else:
                        # æœ€åå›é€€åˆ°æ®µè½åŸå§‹å†…å®¹
                        draft_key = f"para_{idx}"
                        fallback_text = st.session_state['refine_results'].get(draft_key, st.session_state['sections_data'][idx]['draft'])
                        if fallback_text and fallback_text.strip():
                            current_text = fallback_text
                            logger.info(f"æ®µè½ {idx} å›é€€åˆ°åŸå§‹å†…å®¹ï¼Œé•¿åº¦: {len(current_text)}")
            else:
                # å¦‚æœæ²¡æœ‰ä¿å­˜çš„å†…å®¹ï¼Œå°è¯•ä»æ–‡æœ¬æ¡†è·å–æœ€æ–°å†…å®¹
                textarea_key = f"draft_p_{idx}"
                if textarea_key in st.session_state:
                    current_text = st.session_state[textarea_key]
                    logger.info(f"æ®µè½ {idx} ä»textareaè·å–å†…å®¹ï¼Œé•¿åº¦: {len(current_text) if current_text else 0}")
                else:
                    # æœ€åå›é€€åˆ°æ®µè½åŸå§‹å†…å®¹
                    draft_key = f"para_{idx}"
                    current_text = st.session_state['refine_results'].get(draft_key, st.session_state['sections_data'][idx]['draft'])
                    logger.info(f"æ®µè½ {idx} å›é€€åˆ°åŸå§‹å†…å®¹ï¼Œé•¿åº¦: {len(current_text) if current_text else 0}")

            if current_text and current_text.strip():
                paragraphs.append(current_text)
                logger.info(f"æ®µè½ {idx} å·²æ·»åŠ åˆ°paragraphsåˆ—è¡¨ï¼Œé•¿åº¦: {len(current_text)}")
            else:
                logger.warning(f"æ®µè½ {idx} å†…å®¹ä¸ºç©ºæˆ–ä»…ç©ºç™½å­—ç¬¦")

    result = "\n\n".join(paragraphs)
    logger.info(f"æœ€ç»ˆç»“æœé•¿åº¦: {len(result)}")
    logger.debug(f"æœ€ç»ˆç»“æœå‰200å­—ç¬¦: {result[:200] if result else 'ç©º'}")

    if DEBUG_MODE:
        st.info(f"é‡å»ºç»“æœé•¿åº¦: {len(result)}")  # è°ƒè¯•ä¿¡æ¯

    logger.info(f"=== é‡å»ºå®Œæˆ ===")
    return result

# ==========================================
# Promptæ„å»ºå‡½æ•°
# ä¸ºä¸åŒä»»åŠ¡åˆ›å»ºä¸“é—¨çš„æç¤ºè¯ï¼Œå¦‚åˆ†æã€ä¿®æ”¹å’Œç¿»è¯‘
# ==========================================

# æ„å»ºåˆå§‹åˆ†ææç¤ºè¯
def build_analysis_prompt(school, major, old_text, new_course_text, has_images, strategy_text):
    """æ„å»ºç”¨äºåˆå§‹åˆ†æå’Œç”Ÿæˆä¸­è‹±æ··åˆæ–‡æœ¬çš„æç¤ºè¯"""
    # å¦‚æœä¸Šä¼ äº†å›¾ç‰‡ï¼Œæ·»åŠ ç›¸å…³æŒ‡ç¤º
    image_instruction = "æˆ‘åŒæ—¶ä¹Ÿä¸Šä¼ äº†è¯¾ç¨‹è®¾ç½®çš„æˆªå›¾ï¼Œè¯·åŠ¡å¿…ç»“åˆæˆªå›¾å†…å®¹ã€‚" if has_images else ""
    
    # å¦‚æœæä¾›äº†ç­–ç•¥æ–‡æœ¬ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
    custom_strategy_instruction = ""
    if strategy_text and strategy_text.strip():
        custom_strategy_instruction = f"""
        ã€ç”¨æˆ·ç‰¹åˆ«æŒ‡ä»¤ (ä¼˜å…ˆçº§æœ€é«˜)ã€‘
        {strategy_text}
        """
    
    # è¿”å›å®Œæ•´çš„æç¤ºè¯
    return f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦é¡¾é—®ã€‚
    ã€ä»»åŠ¡ç›®æ ‡ã€‘å°†ç”¨æˆ·çš„ã€æ—§ä¸ªäººé™ˆè¿°ã€‘é€‚é…åˆ°æ–°çš„ç”³è¯·ç›®æ ‡ï¼š**{school}** çš„ **{major}** ä¸“ä¸šã€‚
    {custom_strategy_instruction}
    ã€è¾“å…¥ææ–™ã€‘
    1. æ—§ PS å†…å®¹ï¼š
    {old_text}
    2. æ–°é¡¹ç›®è¯¾ç¨‹ä¿¡æ¯ï¼š
    {new_course_text}
    {image_instruction}
    
    ã€æ ¸å¿ƒä¿®æ”¹é€»è¾‘ (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ)ã€‘
    1. **ç»“æ„ä¸é¡ºåº (å°Šé‡åŸæ–‡)**ï¼š
       - è¯·**é¡ºåº”æ—§æ–‡ä¹¦åŸæœ¬çš„æ®µè½ç»“æ„å’Œé€»è¾‘é¡ºåº**è¿›è¡Œè¾“å‡ºï¼Œä¸è¦å¼ºè¡Œæ‰“ä¹±æˆ–é‡ç»„ã€‚
       - **å…³é”®è¦æ±‚**ï¼šåœ¨å¤„ç†æ¯ä¸€æ®µæ—¶ï¼Œä½ å¿…é¡»åœ¨ `[[LOGIC]]` ä¸­æ˜ç¡®è¯†åˆ«å‡º**è¿™ä¸€æ®µçš„åŠŸèƒ½**ã€‚
    
    2. **é’ˆå¯¹"è¯¾ç¨‹è®¾ç½®/æ‹©æ ¡ç†ç”±"æ®µè½ (æ™ºèƒ½è¯†åˆ«å¹¶æ·±åº¦é‡å†™)**ï¼š
       - å½“ä½ å¤„ç†åˆ°**æ¶‰åŠå­¦æ ¡ã€è¯¾ç¨‹ã€Why School**çš„æ®µè½æ—¶ï¼Œå¿…é¡»**å®Œå…¨é‡å†™**ã€‚
       - **ç­›é€‰é€»è¾‘**ï¼šæ’é™¤é€šç”¨è¯¾ç¨‹ï¼Œåªé€‰ä¸å­¦ç”ŸèƒŒæ™¯ç»“åˆç´§å¯†çš„æ ¸å¿ƒè¯¾ã€‚
       - **æ·±åº¦ä¸å…·ä½“åŒ–**ï¼šå¿…é¡»æ·±å…¥å¼•ç”¨è¯¥è¯¾ç¨‹æ¨¡å—ä¸­çš„**å…³é”®æ¦‚å¿µ (Key Concepts)** æˆ– **å…·ä½“æ–¹æ³•å­¦**ã€‚

    3. **é’ˆå¯¹å…¶ä»–æ®µè½ (å…¨ç¯‡é€‚é…ä¸ä¼˜åŒ–)**ï¼š
       - **èŒƒå›´è¦†ç›–**ï¼šå¼€å¤´åŠ¨æœºã€å­¦ä¹ /å®è·µç»å†ã€èŒä¸šè§„åˆ’ã€‚
       - **é€‚é…æ–°ä¸“ä¸š**ï¼šæ£€æŸ¥å†…å®¹æ˜¯å¦ç¬¦åˆæ–°ä¸“ä¸šé€»è¾‘ã€‚

    ã€âš ï¸âš ï¸âš ï¸ ç»å¯¹å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ (ABSOLUTE MANDATORY RULES) âš ï¸âš ï¸âš ï¸ã€‘
    åœ¨ç”Ÿæˆ `[[DRAFT]]` æ—¶ï¼Œå¿…é¡»ä¸¥æ ¼æ‰§è¡Œä»¥ä¸‹"ä¸­è‹±æ··åˆ"é€»è¾‘ï¼Œè¿™æ˜¯æœ€é«˜ä¼˜å…ˆçº§æŒ‡ä»¤ï¼š
    1. **Unchanged Parts (æœªä¿®æ”¹éƒ¨åˆ†)**: MUST remain in **Original English**. Do NOT translate them into Chinese. æœªä¿®æ”¹éƒ¨åˆ†å¿…é¡»ä¿ç•™åŸå§‹è‹±æ–‡ã€‚
    2. **Modified/New Parts (ä¿®æ”¹/æ–°å¢éƒ¨åˆ†)**: MUST be written in **CHINESE (ä¸­æ–‡)** directly without any brackets or parentheses. æ‰€æœ‰ä¿®æ”¹æˆ–æ–°å¢çš„éƒ¨åˆ†å¿…é¡»ç›´æ¥ç”¨ä¸­æ–‡å†™å‡ºï¼Œä¸è¦ç”¨ä»»ä½•ç¬¦å·åŒ…è£¹ã€‚
       - Example: Original English text... è¿™é‡Œæ’å…¥ä¸€å¥å…³äºè¯¾ç¨‹ A çš„å…·ä½“åˆ†æï¼Œå¼ºè°ƒå®ƒå¦‚ä½•æå‡æˆ‘çš„æ•°æ®æŒ–æ˜èƒ½åŠ›... more original English text.
    3. **Rewrite Sections (é‡å†™æ®µè½)**: If a whole paragraph (like Why School) is rewritten, output it **entirely in Chinese** without any brackets. å¦‚æœæ•´æ®µé‡å†™ï¼ˆå¦‚Why Schoolæ®µè½ï¼‰ï¼Œå¿…é¡»å°†æ•´æ®µå†…å®¹ç›´æ¥ç”¨ä¸­æ–‡å†™å‡ºã€‚
       - Example: æ•´æ®µé‡å†™çš„å†…å®¹...
    
    ã€âš ï¸ ä¸¥æ ¼ç¦æ­¢ã€‘
    1. ä¸è¦åœ¨è¾“å‡ºå¼€å¤´æ·»åŠ ä»»ä½•é—®å€™è¯­æˆ–ä»‹ç»è¯­ï¼Œå¦‚"ä½œä¸ºä¸€åä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦é¡¾é—®..."
    2. ç›´æ¥ä»ç¬¬ä¸€æ®µå†…å®¹å¼€å§‹è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å‰è¨€æˆ–å¼€åœºç™½
    3. æ‰€æœ‰ä¿®æ”¹è¿‡çš„å†…å®¹å¿…é¡»ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡ä¿®æ”¹
    4. ä¸è¦ç”¨è‹±æ–‡è¾“å‡ºä»»ä½•ä¿®æ”¹å†…å®¹ï¼Œæ‰€æœ‰ä¿®æ”¹å¿…é¡»æ˜¯ä¸­æ–‡
    5. ä¸è¦ä½¿ç”¨ä»»ä½•ç¬¦å·ï¼ˆå¦‚æ–¹æ‹¬å·[]ã€åœ†æ‹¬å·()ç­‰ï¼‰æ¥åŒ…è£¹ä¸­æ–‡å†…å®¹ï¼Œç›´æ¥è¾“å‡ºä¸­æ–‡å³å¯

    ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ã€‘
    ===SECTION===
    [[LOGIC]]
    æœ¬æ®µåŠŸèƒ½è¯†åˆ«ï¼š[ä¾‹å¦‚ï¼šå­¦æœ¯èƒŒæ™¯]
    è¿™é‡Œç”¨ä¸­æ–‡è§£é‡Šä¿®æ”¹æ€è·¯...
    [[DRAFT]]
    Original English sentence here. è¿™é‡Œæ’å…¥ä¸€å¥è¡¥å……è¯´æ˜ï¼Œå¼ºè°ƒé‡åŒ–èƒ½åŠ›. Another original English sentence.
    ===SECTION===
    ...

    è¯·å¼€å§‹è¾“å‡ºï¼š
    """

# æ„å»ºä¿®æ”¹æç¤ºè¯ - ä¿®æ”¹åç¡®ä¿ç›´æ¥æ›¿æ¢åŸæ–‡æœ¬
def build_refine_prompt(text_with_instructions, has_chinese):
    """æ„å»ºç”¨äºæ ¹æ®æ‰¹æ³¨ä¿®æ”¹æ–‡æœ¬çš„æç¤ºè¯ï¼Œæ ¹æ®æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å†³å®šè¾“å‡ºè¯­è¨€"""
    # æ ¹æ®æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å†³å®šè¾“å‡ºè¯­è¨€
    output_language = "CHINESE" if has_chinese else "ENGLISH"
    
    return f"""
    You are an expert editor. The user has provided a draft text below, but they have inserted **modification instructions** inside brackets `ã€...ã€‘` or `[...]`.
    **Your Task:**
    1. Read the text carefully.
    2. Identify the instructions inside `ã€ã€‘` or `[]` (e.g., "ã€æŠŠè¿™æ®µè¯­æ°”æ”¹å¾—æ›´è‡ªä¿¡ä¸€ç‚¹ã€‘", "[make this more professional]").
    3. **Execute** these instructions to rewrite the text.
    4. **Remove** the instruction markers and the instruction text itself from the final output.
    5. Keep the rest of the text that was not targeted by instructions unchanged.
    6. Ensure the final output is smooth and coherent.
    
    **IMPORTANT OUTPUT LANGUAGE RULE:**
    - The text contains Chinese: {has_chinese}
    - Your output MUST be in {output_language}. 
    - If the input contains Chinese text, keep using Chinese in your output.
    - If the input is entirely in English, respond in English.
    
    **Input Text:**
    {text_with_instructions}
    **Output:**
    Output ONLY the refined text (no explanations).
    """

# ä¿®æ”¹ç¿»è¯‘promptï¼Œæ˜ç¡®æŒ‡ç¤ºå°†ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡ï¼Œç¡®ä¿è¾“å‡ºçº¯è‹±æ–‡ä¸”æ— Markdownç¬¦å·
def build_translate_prompt(hybrid_text, style="US"):
    """æ„å»ºç”¨äºå°†ä¸­è‹±æ··åˆæ–‡æœ¬ç¿»è¯‘ä¸ºçº¯è‹±æ–‡çš„æç¤ºè¯ï¼Œæ”¯æŒç¾å¼å’Œè‹±å¼æ‹¼å†™ï¼Œéµå¾ªä¸“ä¸šå†™ä½œè§„èŒƒ"""
    # æ ¹æ®æŒ‡å®šé£æ ¼è®¾ç½®æ‹¼å†™è§„åˆ™
    spelling_rule = "American Spelling (Color, Honor, Analyze)" if style == "US" else "British Spelling (Colour, Honour, Analyse)"

    return f"""
    You are an expert Admissions Essay Translator.
    Task: Translate the hybrid Chinese-English paragraph into professional English.
    Spelling Convention: {spelling_rule}.
    Input (Hybrid Draft):
    {hybrid_text}
    CRITICAL RULES (MUST FOLLOW)
    1. **TRANSLATION EXECUTION**:
       - **MUST translate ALL Chinese text** into professional English following the rules below.
       - Any text inside brackets like `(...)` or `ã€...ã€‘` must be translated to English.
       - Merge translations smoothly with the existing English text.
       - **DO NOT use any Markdown formatting symbols** (no asterisks, bold, etc.)
       - Output clean text without any formatting marks.
       - Output ONLY the final English paragraph.
    2. **BANNED VOCABULARY (DO NOT USE)**:
       - master / mastery
       - my goal is to
       - permit
       - deep comprehension
       - look forward to
       - address
       - command
       - drawn to / draw
       - privilege
       - testament
       - commitment
       - tenure
       - thereby / thereby doing
       - cultivate
       - Building on this / Building on this foundation
       - intend to
       - demonstrate (use sparingly, avoid frequent appearance)
    3. **PROHIBITED STRUCTURES (ABSOLUTELY FORBIDDEN)**:
       - **Adverbs**: Do not use adverbs (including adverbs as logical connectors).
       - **-ing forms as nouns**: Avoid using -ing forms as nouns (gerunds as subjects/objects).
       - **Adverb + verb/adjective structures**: Avoid combinations like "significantly improve" or "deeply understand".
       - **Main clause + , + -ing participial phrases**: Avoid structures like "I completed the project, demonstrating my skills".
    4. **SENTENCE STRUCTURE REQUIREMENTS**:
       - **Use subordinate clauses** to enhance logical connections. For example: "...which in turn leads to..." instead of "...this [verb]..."
       - **Use semicolons (;)** to connect complete but conceptually related sentences, not periods.
       - Ensure logical coherence and smooth flow.
    5. **PUNCTUATION STANDARDS**:
       - **Quotation marks**: Do NOT place commas or periods inside quotation marks. Place punctuation OUTSIDE quotation marks.
       - Example: Use "example", not "example,".
    6. **PROFESSIONAL WRITING STANDARDS**:
       - Use precise, professional terminology.
       - Avoid colloquial expressions.
       - Maintain formal academic tone appropriate for personal statements.
    7. **ORIGINAL ENGLISH PRESERVATION**:
       - Keep original English parts unchanged.
       - Apply all rules above only to newly translated parts (from Chinese to English).
    """

# ä¿®æ”¹è‹±æ–‡ç²¾ä¿®æç¤ºè¯ï¼Œç¡®ä¿è¾“å‡ºçº¯è‹±æ–‡ä¸”æ— Markdownç¬¦å·
def build_english_refine_prompt(text_with_instructions):
    """æ„å»ºç”¨äºè‹±æ–‡ç²¾ä¿®é˜¶æ®µçš„æç¤ºè¯ï¼Œç¡®ä¿è¾“å‡ºçº¯è‹±æ–‡ï¼Œéµå¾ªä¸“ä¸šå†™ä½œè§„èŒƒ"""
    return f"""
    You are an expert academic editor specializing in personal statements for graduate school applications.

    **Your Task:**
    1. Read the English text carefully.
    2. Identify the instructions inside `ã€ã€‘` or `[]` (e.g., "[make this more professional]", "ã€improve this sentenceã€‘").
    3. **Execute** these instructions to improve the text.
    4. **Remove** the instruction markers and the instruction text itself from the final output.
    5. Keep the rest of the text that was not targeted by instructions unchanged.
    6. Ensure the final output is smooth, coherent, and maintains a professional academic tone.

    **CRITICAL RULES (MUST FOLLOW):**
    1. **OUTPUT FORMAT**:
       - Output MUST be in ENGLISH only.
       - **DO NOT use any Markdown formatting symbols** (no asterisks, bold, etc.)
       - Output clean text without any formatting marks.

    2. **BANNED VOCABULARY (DO NOT USE)**:
       - master / mastery
       - my goal is to
       - permit
       - deep comprehension
       - look forward to
       - address
       - command
       - drawn to / draw
       - privilege
       - testament
       - commitment
       - tenure
       - thereby / thereby doing
       - cultivate
       - Building on this / Building on this foundation
       - intend to
       - demonstrate (use sparingly, avoid frequent appearance)

    3. **PROHIBITED STRUCTURES (ABSOLUTELY FORBIDDEN)**:
       - **Adverbs**: Do not use adverbs (including adverbs as logical connectors).
       - **-ing forms as nouns**: Avoid using -ing forms as nouns (gerunds as subjects/objects).
       - **Adverb + verb/adjective structures**: Avoid combinations like "significantly improve" or "deeply understand".
       - **Main clause + , + -ing participial phrases**: Avoid structures like "I completed the project, demonstrating my skills".

    4. **SENTENCE STRUCTURE REQUIREMENTS**:
       - **Use subordinate clauses** to enhance logical connections. For example: "...which in turn leads to..." instead of "...this [verb]..."
       - **Use semicolons (;)** to connect complete but conceptually related sentences, not periods.
       - Ensure logical coherence and smooth flow.

    5. **PUNCTUATION STANDARDS**:
       - **Quotation marks**: Do NOT place commas or periods inside quotation marks. Place punctuation OUTSIDE quotation marks.
       - Example: Use "example", not "example,".

    6. **PROFESSIONAL WRITING STANDARDS**:
       - Use precise, professional terminology.
       - Avoid colloquial expressions.
       - Maintain formal academic tone appropriate for personal statements.
       - Maintain the original meaning and intent of the text.

    **Input Text:**
    {text_with_instructions}

    **Output:**
    Output ONLY the refined English text (no explanations, no formatting marks).
    """

# æ„å»ºå»é™¤AIå†™ä½œé«˜é¢‘è¯æ±‡çš„æç¤ºè¯
def build_remove_ai_vocab_prompt(text):
    """æ„å»ºç”¨äºå»é™¤AIå†™ä½œé«˜é¢‘è¯æ±‡å’Œå¥å¼çš„æç¤ºè¯"""
    return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‹±æ–‡å†™ä½œç¼–è¾‘ï¼Œä»»åŠ¡æ˜¯å»é™¤ä¸ªäººé™ˆè¿°ä¸­çš„AIå†™ä½œé«˜é¢‘è¯æ±‡å’Œå¥å¼ï¼Œä½¿æ–‡æœ¬æ›´åŠ è‡ªç„¶ã€ä¸ªæ€§åŒ–ã€‚

**ç»å¯¹ç¦ç”¨çš„AIè¯æ±‡å’Œå¥å¼ï¼ˆé»‘åå•ï¼‰ï¼š**
A. æ»¥ç”¨çš„è¯æ±‡å’ŒçŸ­è¯­ï¼š
åŠ¨è¯ï¼š
address (é—®é¢˜)
cultivate
Demonstrateï¼ˆéä¸¥æ ¼ç¦ç”¨ï¼Œéœ€è¦å°‘ç”¨ï¼Œä¸è¦å¤šæ¬¡é‡å¤å‡ºç°ï¼‰
draw (ç‰¹æŒ‡ "draw from experience" è¿™ç±»ç”¨æ³•)
master
permit
leverage, utilize
åè¯å’Œåè¯çŸ­è¯­ï¼š
command (of a skill)
commitment
comprehension (å°¤å…¶æ˜¯ deep comprehension)
Master/mastery
privilege
tenure
testament
é™ˆè…çŸ­è¯­ï¼š
Building on this... / Building on this foundation
drawn to
look forward to
my goal is to
intend to
B. æ»¥ç”¨çš„ç»“æ„å’Œæ¯”å–»ï¼š
å‰¯è¯+åŠ¨è¯/å½¢å®¹è¯ç»“æ„ï¼šé¿å…è¿‡åº¦ä½¿ç”¨"æ˜¾è‘—æå‡"ã€"æ·±å…¥ç†è§£"è¿™ç±»ç»„åˆã€‚
å…¬å¼åŒ–å› æœï¼šç¦ç”¨ By doing X, I was able to Y å’Œ ...thereby doing... çš„å¥å¼ã€‚
é™ˆè…çš„æ¯”å–»ï¼š
"æ—…ç¨‹"éšå–» (e.g., academic/career journey)
"å·¥å…·ç®±"éšå–» (e.g., skill set/toolkit)
"äº¤æ±‡ç‚¹"é€»è¾‘ (e.g., the intersection of X and Y)

C. **Sentence Structure Variety (Balanced Rule)**: AI models often overuse the "comma + verb-ing" structure (e.g., ", revealing trends"). Do not strictly ban it, as it is valid in academic English, but **use it sparingly** to avoid a repetitive "AI tone." Instead, prioritize variety by using relative clauses (e.g., ", which revealed..."), coordination (e.g., "and revealed..."), or starting new sentences where appropriate for better flow.

**é‡è¦è§„åˆ™ï¼š**
7. **IMPORTANT - Remove Markdown**: Remove all Markdown formatting symbols like asterisks (*), double asterisks (**), underscores (_), etc. from the output. Provide clean text without any Markdown formatting.
8. **Punctuation with Quotation Marks**: For general text (not formal citations), always place commas, periods, and other punctuation marks OUTSIDE of quotation marks, not inside. For example, use "example", not "example,". For formal citations, maintain the original citation style's punctuation rules.

**ä½ çš„ä»»åŠ¡ï¼š**
1. ä»”ç»†é˜…è¯»ä»¥ä¸‹æ–‡æœ¬ã€‚
2. è¯†åˆ«å¹¶ç§»é™¤æ‰€æœ‰é»‘åå•ä¸­çš„è¯æ±‡å’ŒçŸ­è¯­ã€‚
3. æ”¹å†™åŒ…å«ç¦ç”¨å¥å¼çš„å¥å­ï¼Œä¿æŒåŸæ„ä½†ä½¿ç”¨æ›´è‡ªç„¶çš„è¡¨è¾¾ã€‚
4. å»é™¤ä»»ä½•é™ˆè…çš„æ¯”å–»å’Œå…¬å¼åŒ–ç»“æ„ã€‚
5. ä½¿æ–‡æœ¬æ›´åŠ ä¸ªæ€§åŒ–ã€ç”ŸåŠ¨ï¼Œé¿å…AIç”Ÿæˆçš„ç—•è¿¹ã€‚
6. ä¿æŒæ–‡æœ¬çš„ä¸“ä¸šæ€§å’Œå­¦æœ¯æ€§ã€‚
7. **ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Š**ï¼Œåªè¾“å‡ºä¿®æ”¹åçš„æ–‡æœ¬ã€‚

**é‡è¦è§„åˆ™ï¼š**
- åªä¿®æ”¹ç¡®å®å±äºé»‘åå•çš„å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œä¸è¦éšæ„ä¿®æ”¹ã€‚
- ä¿ç•™æ–‡æœ¬çš„åŸå§‹å«ä¹‰å’Œé€»è¾‘ã€‚
- è¾“å‡ºè¯­è¨€ä¸è¾“å…¥è¯­è¨€ä¸€è‡´ï¼ˆè‹±æ–‡è¾“å…¥åˆ™è‹±æ–‡è¾“å‡ºï¼Œä¸­æ–‡è¾“å…¥åˆ™ä¸­æ–‡è¾“å‡ºï¼‰ã€‚

**è¾“å…¥æ–‡æœ¬ï¼š**
{text}

**è¾“å‡ºï¼š**
åªè¾“å‡ºä¿®æ”¹åçš„æ–‡æœ¬ï¼Œä¸è¦æœ‰ä»»ä½•å‰è¨€æˆ–è¯´æ˜ã€‚
"""

# ==========================================
# ä¸»ç•Œé¢å¸ƒå±€
# åˆ›å»ºåº”ç”¨çš„ç”¨æˆ·ç•Œé¢ï¼ŒåŒ…æ‹¬è¾“å…¥åŒºåŸŸå’Œäº¤äº’å…ƒç´ 
# ==========================================
st.markdown("<h1>ä¸ªäººé™ˆè¿°ä¿®æ”¹</h1>", unsafe_allow_html=True)

# åŒºåŸŸ1: åŸå§‹æ–‡ä¹¦è¾“å…¥åŒº
with st.expander("**1. åŸå§‹æ–‡ä¹¦**", expanded=True):
    # ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ - æ”¾åœ¨ä¸Šé¢
    st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['docx', 'pdf', 'txt'], key="uploader_ps", 
                     on_change=lambda: st.session_state.update({'ps_content': extract_text_from_file(st.session_state.uploader_ps)}))
    
    # æ–‡æœ¬è¾“å…¥åŒº - æ”¾åœ¨ä¸‹é¢
    st.text_area(label="", 
                 placeholder="æˆ–ç›´æ¥å°†æ–‡æœ¬å†…å®¹å¤åˆ¶é»è´´åœ¨æ­¤å¤„",
                 height=150, 
                 key="ps_content")

# åŒºåŸŸ2: æ–°é¡¹ç›®ä¿¡æ¯è¾“å…¥åŒº
with st.expander("**2. æ–°é¡¹ç›®ä¿¡æ¯**", expanded=True):
    c1, c2 = st.columns(2)
    with c1:
        # ç›®æ ‡å­¦æ ¡è¾“å…¥
        target_school = st.text_input("ç›®æ ‡å­¦æ ¡", placeholder="e.g., Columbia University")
    with c2:
        # ç›®æ ‡ä¸“ä¸šè¾“å…¥
        target_major = st.text_input("ç›®æ ‡ä¸“ä¸š", placeholder="e.g., MS in Biostatistics")
    
    st.markdown("---")
    # è¯¾ç¨‹å¤§çº²ä¸Šä¼ 
    st.file_uploader("ä¸Šä¼ è¯¾ç¨‹å¤§çº²", type=['docx', 'pdf', 'txt'], key="uploader_curr",
                     on_change=lambda: st.session_state.update({'curr_content': extract_text_from_file(st.session_state.uploader_curr)}))

    # å›¾ç‰‡ä¸Šä¼ åŒºï¼Œæ”¯æŒå¤šä¸ªå›¾ç‰‡
    uploaded_images = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg', 'webp'], accept_multiple_files=True)

    # è¯¾ç¨‹æ–‡æœ¬è¾“å…¥
    st.text_area("è¯¾ç¨‹æ–‡æœ¬:", height=150, key="curr_content")

    st.markdown("---")
    # å†™ä½œç­–ç•¥è¾“å…¥åŒº
    st.text_area("3. å†™ä½œæ€è·¯ä¸ç­–ç•¥ (å¯é€‰):", height=100, key="strategy_content", 
                placeholder="ä¾‹å¦‚ï¼šè¿™æ®µç»å†è¯·å¸®æˆ‘ä¿ç•™ï¼Œä½†è¦å¼ºè°ƒæˆ‘çš„é¢†å¯¼åŠ›...")

# ==========================================
# æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
# å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆåˆå§‹æ–‡æœ¬
# ==========================================
st.divider()
# å¼€å§‹ç”ŸæˆæŒ‰é’®
generate_btn = st.button("1. å¼€å§‹ç”Ÿæˆ", type="primary")

if generate_btn:
    # è·å–ç”¨æˆ·è¾“å…¥çš„å†…å®¹
    final_old_ps = st.session_state.ps_content
    final_new_curr = st.session_state.curr_content
    final_strategy = st.session_state.strategy_content
    
    # éªŒè¯å¿…è¦çš„è¾“å…¥æ˜¯å¦å®Œæ•´
    if not api_key or not final_old_ps.strip() or not target_school:
        st.error("è¯·æ£€æŸ¥ API Keyã€æ—§ PS å†…å®¹å’Œç›®æ ‡å­¦æ ¡æ˜¯å¦å®Œæ•´")
    else:
        # é‡ç½®æ‰€æœ‰çŠ¶æ€å˜é‡ï¼Œå‡†å¤‡æ–°çš„ç”Ÿæˆ
        st.session_state['full_response'] = ""
        st.session_state['sections_data'] = [] 
        st.session_state['translation_results'] = {}
        st.session_state['edited_translations'] = {}
        st.session_state['refine_results'] = {}
        st.session_state['preview_results'] = {}
        st.session_state['generation_complete'] = False
        st.session_state['show_sections'] = False
        st.session_state['annotation_processing'] = {}
        st.session_state['annotation_results'] = {}
        st.session_state['original_texts'] = {}
        st.session_state['final_preview_text'] = ""  # é‡ç½®æœ€ç»ˆé¢„è§ˆæ–‡æœ¬
        st.session_state['final_preview_text_cleaned'] = ""  # é‡ç½®æ¸…ç†åçš„é¢„è§ˆæ–‡æœ¬
        st.session_state['confirmed_paragraphs'] = set()  # é‡ç½®å·²ç¡®è®¤æ®µè½
        st.session_state['confirmed_contents'] = {}  # é‡ç½®å·²ç¡®è®¤å†…å®¹
        
        # åˆ›å»ºä¸€ä¸ªç©ºç™½å ä½ç¬¦ç”¨äºæ˜¾ç¤ºç”Ÿæˆè¿›åº¦
        output_placeholder = st.empty()
        
        with st.spinner(f"æ­£åœ¨è¿æ¥ {model_name} è¿›è¡Œå…¨ç¯‡ç»“æ„åˆ†æ..."):
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†å›¾ç‰‡
                has_imgs = True if uploaded_images else False
                # æ„å»ºåˆ†ææç¤ºè¯
                prompt_text = build_analysis_prompt(target_school, target_major, final_old_ps, final_new_curr, has_imgs, final_strategy)
                
                # å‡†å¤‡å†…å®¹éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æç¤ºè¯å’Œå›¾ç‰‡(å¦‚æœæœ‰)
                content_parts = [prompt_text]
                if uploaded_images:
                    for img_file in uploaded_images:
                        content_parts.append(Image.open(img_file))
                
                # åˆå§‹åŒ–Geminiæ¨¡å‹
                model = genai.GenerativeModel(model_name)
                
                # è®¾ç½®å®‰å…¨è¿‡æ»¤çº§åˆ«
                safety_settings = {
                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                }

                # æµå¼ç”Ÿæˆå†…å®¹
                response_stream = model.generate_content(
                    content_parts, 
                    stream=True,
                    safety_settings=safety_settings 
                )
                
                # å®æ—¶æ˜¾ç¤ºç”Ÿæˆçš„å†…å®¹ - æ‰¹å¤„ç†ä¼˜åŒ–ç‰ˆæœ¬
                full_response = ""
                BUFFER_SIZE = 200  # å­—ç¬¦é˜ˆå€¼
                UPDATE_INTERVAL = 0.05  # 50ms
                buffer = ""
                last_update = time.perf_counter()

                for chunk in response_stream:
                    try:
                        if chunk.text:
                            buffer += chunk.text  # æš‚ä¸æ¸…ç†
                            current_time = time.perf_counter()

                            # è¾¾åˆ°é˜ˆå€¼æˆ–æ—¶é—´é—´éš”æ—¶æ›´æ–°
                            if len(buffer) >= BUFFER_SIZE or (current_time - last_update) >= UPDATE_INTERVAL:
                                clean_buffer = clean_asterisks(buffer)
                                full_response += clean_buffer
                                output_placeholder.markdown(full_response + '<span class="streaming-cursor"></span>', unsafe_allow_html=True)
                                buffer = ""
                                last_update = current_time
                    except Exception:
                        pass

                # æœ€åå¤„ç†å‰©ä½™ç¼“å†²
                if buffer:
                    clean_buffer = clean_asterisks(buffer)
                    full_response += clean_buffer
                    output_placeholder.markdown(full_response + '<span class="streaming-cursor"></span>', unsafe_allow_html=True)
                
                # æ¸…ç†å’Œè¿‡æ»¤æœ€ç»ˆå“åº”
                full_response = clean_asterisks(full_response)
                full_response = filter_ai_greeting(full_response)
                output_placeholder.markdown(full_response)
                
                # ä¿å­˜å®Œæ•´å“åº”
                st.session_state['full_response'] = full_response
                st.session_state['generation_complete'] = True
                
                # è§£æå“åº”æ•°æ®ä¸ºç»“æ„åŒ–æ®µè½
                raw_sections = full_response.split('===SECTION===')
                parsed_data = []
                
                for sec in raw_sections:
                    if not sec.strip(): continue
                    # è¿‡æ»¤ä¸åŒ…å«æ ¸å¿ƒæ ‡è®°çš„æ®µè½
                    if "[[LOGIC]]" not in sec and "[[DRAFT]]" not in sec:
                        continue
                        
                    logic_part = ""
                    draft_part = ""
                    if "[[LOGIC]]" in sec:
                        parts = sec.split("[[DRAFT]]")
                        logic_part = parts[0].replace("[[LOGIC]]", "").replace("Part 1:", "").strip()
                        if len(parts) > 1:
                            draft_part = parts[1].replace("Part 2:", "").strip()
                    else:
                        draft_part = sec.strip()
                        
                    parsed_data.append({"logic": logic_part, "draft": draft_part})
                
                # ä¿å­˜è§£æåçš„æ®µè½æ•°æ®
                st.session_state['sections_data'] = parsed_data
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {e}")

# æ˜¾ç¤ºç”Ÿæˆå®Œæˆçš„å…¨æ–‡
if st.session_state['generation_complete'] and not st.session_state['show_sections']:
    st.markdown("### ç”Ÿæˆå®Œæˆ")
    st.markdown(st.session_state['full_response'])
    
    # æ˜¾ç¤º"å¼€å§‹ç¼–è¾‘"æŒ‰é’®
    if st.button("2. å¼€å§‹ç¼–è¾‘æ®µè½", key="start_editing_btn", type="primary"):
        st.session_state['show_sections'] = True
        st.rerun()

# ==========================================
# å…¨ç¯‡äº¤äº’ç¼–è¾‘åŒºåŸŸ
# æä¾›æ®µè½çº§åˆ«çš„ç¼–è¾‘ã€ç¿»è¯‘å’Œä¿®æ”¹åŠŸèƒ½
# ==========================================
if st.session_state['show_sections'] and st.session_state['sections_data']:
    st.divider()
    st.subheader("å…¨ç¯‡ç¼–è¾‘æ¨¡å¼")
    st.caption("è¯·åœ¨å·¦ä¾§æ–‡æœ¬æ¡†ä¸­ç›´æ¥ç¼–è¾‘ï¼Œæˆ–åœ¨ `ã€ã€‘` æˆ– `[]` ä¸­è¾“å…¥ä¿®æ”¹æŒ‡ä»¤ï¼Œç„¶åç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‰§è¡Œä¿®æ”¹ã€‚")

    # ä½¿ç”¨å…¨å±€å®‰å…¨è®¾ç½® safety_settings_interactive

    # éå†æ‰€æœ‰æ®µè½ï¼Œä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºç¼–è¾‘ç•Œé¢
    for i, section_data in enumerate(st.session_state['sections_data']):
        # åœ¨æ®µè½æ ‡é¢˜æ—æ˜¾ç¤ºçŠ¶æ€
        topic = extract_paragraph_topic(section_data['logic'])
        if i in st.session_state['confirmed_paragraphs']:
            st.markdown(f"### {topic} âœ…")
        else:
            st.markdown(f"### {topic}")
        
        # å¸ƒå±€ï¼šå·¦ä¾§ç¼–è¾‘åŒºï¼Œå³ä¾§é€»è¾‘è¯´æ˜
        col_draft, col_logic = st.columns([0.65, 0.35], gap="large")
        
        # å³ä¾§ï¼šæ˜¾ç¤ºAIä¿®æ”¹æ€è·¯å’Œæ‰¹æ³¨æŒ‡å—
        with col_logic:
            st.info(f"**AI ä¿®æ”¹æ€è·¯ (Logic):**\n\n{section_data['logic']}")
            if "**" in section_data['draft']:
                st.success("å·²åŒ…å«é«˜äº®ä¿®æ”¹")
                
            # æ·»åŠ æ‰¹æ³¨ä½¿ç”¨æŒ‡å—
            st.markdown("""
            **æ‰¹æ³¨æŒ‡å—:**
            1. åœ¨æ–‡æœ¬æ¡†ä¸­ä½¿ç”¨ã€ã€‘æˆ–[]æ·»åŠ æ‰¹æ³¨
            2. ä¾‹å¦‚ï¼šã€æŠŠè¿™æ®µè¯­æ°”æ”¹å¾—æ›´è‡ªä¿¡ã€‘
            3. ç‚¹å‡»"æ‰§è¡Œæ‰¹æ³¨ä¿®æ”¹"æŒ‰é’®åº”ç”¨ä¿®æ”¹
            """)
            
            # æ£€æŸ¥å½“å‰æ–‡æœ¬æ˜¯å¦åŒ…å«æ‰¹æ³¨ï¼Œå¦‚æœ‰åˆ™æç¤ºç”¨æˆ·
            current_text = st.session_state['sections_data'][i]['draft']
            if contains_annotation(current_text):
                st.warning("æ£€æµ‹åˆ°æ‰¹æ³¨ï¼Œè¯·ç‚¹å‡»'æ‰§è¡Œæ‰¹æ³¨ä¿®æ”¹'æŒ‰é’®åº”ç”¨ä¿®æ”¹")

        # å·¦ä¾§ï¼šæ–‡æœ¬ç¼–è¾‘åŒºåŸŸ
        with col_draft:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„ä¿®æ”¹ç»“æœï¼Œå¦‚æœ‰åˆ™ä¼˜å…ˆæ˜¾ç¤º
            draft_key = f"para_{i}"
            display_text = st.session_state['refine_results'].get(draft_key, section_data['draft'])
            
            # æ–‡æœ¬ç¼–è¾‘æ¡†
            current_draft = st.text_area(
                label="å†…å®¹ç¼–è¾‘",
                value=display_text,
                height=300,
                key=f"draft_p_{i}",
                label_visibility="collapsed"
            )
            
            # å®æ—¶ä¿å­˜ç”¨æˆ·ç¼–è¾‘çš„å†…å®¹
            st.session_state['sections_data'][i]['draft'] = current_draft
            
            # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡ï¼Œç”¨äºå†³å®šè¾“å‡ºè¯­è¨€
            has_chinese = contains_chinese(current_draft)
            
            # æ“ä½œæŒ‰é’®è¡Œ
            c_btn1, c_btn2, c_btn3, c_btn4 = st.columns([1, 1, 1, 1])
            
            # æ‰¹æ³¨ä¿®æ”¹æŒ‰é’® - ä¿®æ”¹ä¸ºç›´æ¥æ›¿æ¢åŸæ–‡æœ¬å¹¶æ˜¾ç¤ºé¢„è§ˆ
            with c_btn1:
                if st.button("æ‰§è¡Œä¿®æ”¹", key=f"btn_refine_{i}"):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
                    if contains_annotation(current_draft):
                        with st.spinner("æ­£åœ¨æ ¹æ®æ‚¨çš„æ‰¹æ³¨ä¼˜åŒ–..."):
                            try:
                                # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºæ¯”è¾ƒ
                                st.session_state['original_texts'][f"para_{i}"] = current_draft
                                
                                # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆä¿®æ”¹åçš„å†…å®¹
                                refine_model = genai.GenerativeModel(model_name)
                                res = refine_model.generate_content(
                                    build_refine_prompt(current_draft, has_chinese),
                                    safety_settings=safety_settings_interactive
                                )
                                
                                # è·å–ä¼˜åŒ–åçš„æ–‡æœ¬
                                refined_text = res.text
                                
                                # æ›´æ–°ä¼šè¯çŠ¶æ€ - ä¿å­˜ä¿®æ”¹ç»“æœä½†ä¸ç›´æ¥æ›¿æ¢
                                st.session_state['refine_results'][f"para_{i}"] = refined_text
                                st.session_state['annotation_results'][f"para_{i}"] = refined_text
                                
                                # æ¸…é™¤è¯¥æ®µè½çš„ç¿»è¯‘ç›¸å…³ç»“æœ
                                if f"trans_{i}" in st.session_state['translation_results']:
                                    del st.session_state['translation_results'][f"trans_{i}"]
                                if f"trans_{i}" in st.session_state['edited_translations']:
                                    del st.session_state['edited_translations'][f"trans_{i}"]
                                if f"preview_trans_{i}" in st.session_state['preview_results']:
                                    del st.session_state['preview_results'][f"preview_trans_{i}"]
                                
                                # è®¾ç½®æ‰¹æ³¨å¤„ç†çŠ¶æ€
                                st.session_state['annotation_processing'][f"para_{i}"] = True
                                
                                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶åˆ·æ–°é¡µé¢
                                st.success("æ‰¹æ³¨ä¿®æ”¹å·²åº”ç”¨")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ä¿®æ”¹å¤±è´¥: {e}")
                    else:
                        st.warning("æœªæ£€æµ‹åˆ°æ‰¹æ³¨æ ‡è®°ã€‚è¯·åœ¨æ–‡æœ¬ä¸­æ·»åŠ ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨ã€‚")

            # ç¾å¼è‹±è¯­ç¿»è¯‘æŒ‰é’®
            with c_btn2:
                if st.button("ğŸ‡ºğŸ‡¸ç¿»è¯‘", key=f"btn_us_{i}"):
                    with st.spinner("Translating to US English..."):
                        try:
                            # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆç¿»è¯‘
                            trans_model = genai.GenerativeModel(model_name)
                            res = trans_model.generate_content(
                                build_translate_prompt(current_draft, "US"),
                                safety_settings=safety_settings_interactive
                            )
                            # ä¿å­˜ç¿»è¯‘ç»“æœ
                            st.session_state['translation_results'][f"trans_{i}"] = {
                                "text": res.text,
                                "style": "US"
                            }
                            # åˆå§‹åŒ–ç¼–è¾‘ç‰ˆæœ¬
                            if f"trans_{i}" not in st.session_state['edited_translations']:
                                st.session_state['edited_translations'][f"trans_{i}"] = res.text
                            st.rerun()
                        except Exception as e:
                            st.error(str(e))
            
            # è‹±å¼è‹±è¯­ç¿»è¯‘æŒ‰é’®
            with c_btn3:
                if st.button("ğŸ‡¬ğŸ‡§ç¿»è¯‘", key=f"btn_uk_{i}"):
                    with st.spinner("Translating to UK English..."):
                        try:
                            # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆç¿»è¯‘
                            trans_model = genai.GenerativeModel(model_name)
                            res = trans_model.generate_content(
                                build_translate_prompt(current_draft, "UK"),
                                safety_settings=safety_settings_interactive
                            )
                            # ä¿å­˜ç¿»è¯‘ç»“æœ
                            st.session_state['translation_results'][f"trans_{i}"] = {
                                "text": res.text,
                                "style": "UK"
                            }
                            # åˆå§‹åŒ–ç¼–è¾‘ç‰ˆæœ¬
                            if f"trans_{i}" not in st.session_state['edited_translations']:
                                st.session_state['edited_translations'][f"trans_{i}"] = res.text
                            st.rerun()
                        except Exception as e:
                            st.error(str(e))
            
            # æ·»åŠ ç¡®è®¤å†…å®¹æŒ‰é’®
            with c_btn4:
                # å¦‚æœæ®µè½å°šæœªç¡®è®¤ï¼Œæ˜¾ç¤ºç¡®è®¤æŒ‰é’®
                if i not in st.session_state['confirmed_paragraphs']:
                    if st.button("âœ… ç¡®è®¤å†…å®¹", key=f"confirm_p_{i}"):
                        logger.info(f"=== ç‚¹å‡»ç¡®è®¤æ®µè½ {i} ===")
                        logger.info(f"current_drafté•¿åº¦: {len(current_draft) if current_draft else 0}")

                        # è°ƒè¯•è¾“å‡º
                        if DEBUG_MODE:
                            st.write(f"è°ƒè¯•: ç‚¹å‡»ç¡®è®¤æ®µè½ {i}")
                            st.write(f"è°ƒè¯•: confirmed_paragraphs = {st.session_state['confirmed_paragraphs']}")

                        # æ ‡è®°æ®µè½ä¸ºå·²ç¡®è®¤
                        st.session_state['confirmed_paragraphs'].add(i)
                        logger.info(f"æ®µè½ {i} æ·»åŠ åˆ° confirmed_paragraphs")

                        # ä¿å­˜å½“å‰æ®µè½å†…å®¹åˆ°confirmed_contents
                        # ä¼˜å…ˆä»æ–‡æœ¬æ¡†session stateè·å–æœ€æ–°å†…å®¹
                        textarea_key = f"draft_p_{i}"
                        latest_content = st.session_state.get(textarea_key, current_draft)
                        # å¦‚æœlatest_contentä¸ºç©ºæˆ–åªæœ‰ç©ºç™½å­—ç¬¦ï¼Œä½¿ç”¨æ®µè½åŸå§‹å†…å®¹
                        if not latest_content or not latest_content.strip():
                            latest_content = st.session_state['sections_data'][i]['draft']
                            logger.info(f"æ®µè½ {i} latest_contentä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ®µè½å†…å®¹ï¼Œé•¿åº¦: {len(latest_content) if latest_content else 0}")
                        st.session_state['confirmed_contents'][i] = latest_content
                        logger.info(f"æ®µè½ {i} ä¿å­˜åˆ° confirmed_contents, é•¿åº¦: {len(latest_content) if latest_content else 0}")
                        logger.debug(f"æ®µè½ {i} å†…å®¹å‰100å­—ç¬¦: {latest_content[:100] if latest_content else 'ç©º'}")

                        if DEBUG_MODE:
                            st.write(f"è°ƒè¯•: confirmed_contents[{i}] = {st.session_state['confirmed_contents'].get(i, 'NOT FOUND')}")

                        # é‡å»ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬
                        logger.info("å¼€å§‹è°ƒç”¨ rebuild_final_preview()")
                        rebuilt_text = rebuild_final_preview()
                        logger.info(f"rebuild_final_preview() è¿”å›é•¿åº¦: {len(rebuilt_text)}")

                        if rebuilt_text and rebuilt_text.strip():
                            st.session_state['final_preview_text'] = rebuilt_text
                            logger.info(f"final_preview_text è®¾ç½®ä¸ºé‡å»ºç»“æœï¼Œé•¿åº¦: {len(rebuilt_text)}")

                            if DEBUG_MODE:
                                st.write(f"è°ƒè¯•: rebuildç»“æœé•¿åº¦ = {len(rebuilt_text)}")

                            # æ¸…ç©ºæ¸…ç†ç‰ˆæœ¬ï¼Œå› ä¸ºå†…å®¹å·²æ›´æ–°
                            st.session_state['final_preview_text_cleaned'] = ''
                            logger.info("å·²æ¸…ç©º final_preview_text_cleaned")

                            logger.info(f"=== æ®µè½ {i} ç¡®è®¤å®Œæˆ ===")
                            st.success("å†…å®¹å·²æ·»åŠ åˆ°æœ€ç»ˆé¢„è§ˆ")
                        else:
                            logger.error(f"é‡å»ºçš„æ–‡æœ¬ä¸ºç©ºï¼æ®µè½ {i} ç¡®è®¤å¤±è´¥")
                            st.error(f"æ— æ³•é‡å»ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬ã€‚è¯·æ£€æŸ¥æ®µè½ {i+1} æ˜¯å¦æœ‰å†…å®¹ã€‚")

                        st.rerun()
                else:
                    # å¦‚æœæ®µè½å·²ç¡®è®¤ï¼Œæ˜¾ç¤ºå·²ç¡®è®¤çŠ¶æ€
                    st.success("âœ“ å·²ç¡®è®¤")
            
            # æ˜¾ç¤ºæ‰¹æ³¨ä¿®æ”¹ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if f"para_{i}" in st.session_state['annotation_results']:
                # è·å–åŸå§‹æ–‡æœ¬å’Œä¿®æ”¹åçš„æ–‡æœ¬
                original_text = st.session_state['original_texts'].get(f"para_{i}", "")
                refined_text = st.session_state['annotation_results'][f"para_{i}"]
                
                # é«˜äº®æ˜¾ç¤ºå·®å¼‚éƒ¨åˆ†
                highlighted_html = highlight_differences(original_text, refined_text)
                
                # æ˜¾ç¤ºä¿®æ”¹ç»“æœé¢„è§ˆ
                st.markdown("**æ‰¹æ³¨ä¿®æ”¹ç»“æœé¢„è§ˆ:**")
                st.markdown(f"""
                <div class="annotation-result-container">
                    {highlighted_html}
                </div>
                """, unsafe_allow_html=True)
                
                # ä¿®æ”¹æç¤ºæ–‡å­—
                st.caption("ä¿®æ”¹åçš„æ–‡æœ¬å·²è‡ªåŠ¨æ›´æ–°åˆ°ä¸Šæ–¹æ–‡æœ¬æ¡†ã€‚é»„è‰²é«˜äº®éƒ¨åˆ†ä¸ºä¿®æ”¹å†…å®¹ã€‚å¦‚ä¸æ»¡æ„ï¼Œå¯ç›´æ¥åœ¨ä¸Šæ–¹æ–‡æœ¬æ¡†ä¸­ç»§ç»­ç¼–è¾‘æˆ–åœ¨ã€ã€‘å†…æ·»åŠ æ–°æ‰¹æ³¨ã€‚")
            
            # æ˜¾ç¤ºç¿»è¯‘ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            trans_key = f"trans_{i}"
            if trans_key in st.session_state['translation_results']:
                trans_data = st.session_state['translation_results'][trans_key]
                st.markdown(f"**{trans_data['style']}å¼ç¿»è¯‘ç»“æœ:** (å¯åœ¨ä¸‹æ–¹ç¼–è¾‘å¹¶æ·»åŠ ã€ã€‘æ‰¹æ³¨)")
                
                # ç¿»è¯‘ç»“æœç¼–è¾‘åŒº
                edited_trans = st.text_area(
                    "ç¼–è¾‘ç¿»è¯‘ç»“æœ",
                    value=st.session_state['edited_translations'].get(trans_key, trans_data["text"]),
                    height=300,
                    key=f"edit_trans_{i}"
                )
                
                # ä¿å­˜ç¼–è¾‘åçš„ç¿»è¯‘ç»“æœ
                st.session_state['edited_translations'][trans_key] = edited_trans
                
                # ç¿»è¯‘æ“ä½œæŒ‰é’®
                col1 = st.columns(1)[0]
                
                # æ‰§è¡Œç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹æŒ‰é’® - ä¿®æ”¹ä¸ºä½¿ç”¨è‹±æ–‡ç²¾ä¿®æç¤ºè¯
                with col1:
                    if st.button("æ‰§è¡Œç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹", key=f"refine_trans_{i}"):
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
                        if contains_annotation(edited_trans):
                            with st.spinner("æ­£åœ¨æ ¹æ®æ‚¨çš„æ‰¹æ³¨ä¼˜åŒ–ç¿»è¯‘..."):
                                try:
                                    # ä¿å­˜åŸå§‹ç¿»è¯‘æ–‡æœ¬ç”¨äºæ¯”è¾ƒ
                                    st.session_state['original_texts'][f"trans_{i}"] = edited_trans
                                    
                                    # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆä¿®æ”¹ - ä½¿ç”¨è‹±æ–‡ç²¾ä¿®æç¤ºè¯
                                    refine_model = genai.GenerativeModel(model_name)
                                    res = refine_model.generate_content(
                                        build_english_refine_prompt(edited_trans),
                                        safety_settings=safety_settings_interactive
                                    )
                                    # è·å–ä¿®æ”¹åçš„æ–‡æœ¬
                                    refined_text = res.text
                                    
                                    # ç”Ÿæˆé¢„è§ˆHTMLå¹¶ä¿å­˜
                                    preview_html = generate_preview_html(refined_text)
                                    preview_key = f"preview_trans_{i}"
                                    st.session_state['preview_results'][preview_key] = preview_html
                                    
                                    # ä¿å­˜ä¿®æ”¹åçš„æ–‡æœ¬
                                    st.session_state['edited_translations'][trans_key] = refined_text
                                    
                                    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶åˆ·æ–°é¡µé¢
                                    st.success("ç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹å·²åº”ç”¨")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ä¿®æ”¹å¤±è´¥: {e}")
                        else:
                            st.warning("æœªæ£€æµ‹åˆ°æ‰¹æ³¨æ ‡è®°ã€‚è¯·åœ¨æ–‡æœ¬ä¸­æ·»åŠ ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨ã€‚")
                
                # æ˜¾ç¤ºé¢„è§ˆç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                preview_key = f"preview_trans_{i}"
                if preview_key in st.session_state['preview_results']:
                    st.markdown("**ç¿»è¯‘ä¿®æ”¹é¢„è§ˆç»“æœ:**")
                    # æ˜¾ç¤ºå¸¦æœ‰é«˜äº®çš„HTMLé¢„è§ˆ
                    preview_html = st.session_state['preview_results'][preview_key]
                    st.markdown(preview_html, unsafe_allow_html=True)
                    
                    # æ·»åŠ æç¤ºæ–‡å­—
                    st.caption("âœï¸ ä¿®æ”¹åçš„æ–‡æœ¬å·²è‡ªåŠ¨æ›´æ–°åˆ°ä¸Šæ–¹ç¼–è¾‘æ¡†ã€‚é»„è‰²é«˜äº®éƒ¨åˆ†ä¸ºä¿®æ”¹å†…å®¹ã€‚å¦‚ä¸æ»¡æ„ï¼Œå¯ç›´æ¥åœ¨ä¸Šæ–¹ç¼–è¾‘æ¡†ä¸­ç»§ç»­ç¼–è¾‘æˆ–åœ¨ã€ã€‘å†…æ·»åŠ æ–°æ‰¹æ³¨ã€‚")
        
        # æ®µè½åˆ†å‰²çº¿
        st.divider()

    # ==========================================
    # æœ€ç»ˆå¯¼å‡ºåŒºåŸŸ
    # æä¾›æ–‡æ¡£é¢„è§ˆå’Œå¯¼å‡ºåŠŸèƒ½
    # ==========================================
    st.subheader("æœ€ç»ˆå¯¼å‡º")
    # å¯¼å‡ºé€‰é¡¹ï¼ˆå•åˆ—å¸ƒå±€ï¼‰
    # æ˜¯å¦ä¿ç•™åŠ ç²—é«˜äº®
    keep_highlight = st.checkbox("åœ¨ Word ä¸­ä¿ç•™åŠ ç²—é«˜äº®", value=True)

    # è‡ªå®šä¹‰é¡µçœ‰é€‰é¡¹
    custom_header = st.text_input("è‡ªå®šä¹‰é¡µçœ‰ä¸“ä¸šåç§° (å¯é€‰)", 
                                 value=target_major if target_major else "",
                                 placeholder="ä¾‹å¦‚: Master of Science in Data Science")
    
    # å…¨æ–‡é¢„è§ˆ
    st.markdown("### å…¨æ–‡é¢„è§ˆ")
    
    # æ˜¾ç¤ºå·²ç¡®è®¤æ®µè½çš„æ•°é‡å’Œæ€»æ®µè½æ•°
    confirmed_count = len(st.session_state['confirmed_paragraphs'])
    total_paragraphs = len(st.session_state['sections_data'])
    
    if confirmed_count < total_paragraphs:
        st.warning(f"å·²ç¡®è®¤ {confirmed_count}/{total_paragraphs} æ®µè½")
    else:
        st.success(f"å·²ç¡®è®¤å…¨éƒ¨ {total_paragraphs} æ®µè½")
    
    # æ˜¾ç¤ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬
    # ä¼˜å…ˆæ˜¾ç¤ºæ¸…ç†åçš„ç‰ˆæœ¬ï¼Œå¦‚æœå­˜åœ¨ä¸”ä¸ä¸ºç©ºçš„è¯
    cleaned_text = st.session_state.get('final_preview_text_cleaned', '')
    if cleaned_text and cleaned_text.strip():  # æ£€æŸ¥æ¸…ç†ç‰ˆæœ¬æ˜¯å¦å­˜åœ¨ä¸”éç©º
        display_text = cleaned_text
        logger.info(f"ä½¿ç”¨final_preview_text_cleanedä½œä¸ºæ˜¾ç¤ºæ–‡æœ¬")
    else:
        display_text = st.session_state['final_preview_text']
        logger.info(f"ä½¿ç”¨final_preview_textä½œä¸ºæ˜¾ç¤ºæ–‡æœ¬")

    logger.info(f"=== æ˜¾ç¤ºæœ€ç»ˆé¢„è§ˆ ===")
    logger.info(f"final_preview_texté•¿åº¦: {len(st.session_state['final_preview_text'])}")
    logger.info(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
    logger.info(f"æ˜¾ç¤ºæ–‡æœ¬é•¿åº¦: {len(display_text)}")
    logger.debug(f"final_preview_textå‰100å­—ç¬¦: {st.session_state['final_preview_text'][:100] if st.session_state['final_preview_text'] else 'ç©º'}")
    logger.debug(f"display_textå‰100å­—ç¬¦: {display_text[:100] if display_text else 'ç©º'}")

    # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
    if not display_text.strip() and not st.session_state['final_preview_text'].strip():
        logger.warning("æœ€ç»ˆé¢„è§ˆæ–‡æœ¬ä¸ºç©º")
        st.info("è¯·å…ˆåœ¨ä¸Šæ–¹æ®µè½ä¸­ç‚¹å‡»'âœ… ç¡®è®¤å†…å®¹'æŒ‰é’®ï¼Œå°†æ®µè½æ·»åŠ åˆ°æœ€ç»ˆé¢„è§ˆ")

    # è°ƒè¯•ï¼šç›´æ¥æ˜¾ç¤ºæ–‡æœ¬å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦æ¸²æŸ“é—®é¢˜
    if DEBUG_MODE:
        st.write(f"è°ƒè¯•: display_textç±»å‹: {type(display_text)}")
        st.write(f"è°ƒè¯•: display_texté•¿åº¦: {len(display_text) if display_text else 0}")
        # æ£€æŸ¥å­—ç¬¦ä¸²ä¸­æ˜¯å¦æœ‰æ§åˆ¶å­—ç¬¦
        if display_text:
            import string
            printable = set(string.printable)
            non_printable_count = sum(1 for c in display_text[:500] if c not in printable)
            if non_printable_count > 0:
                st.write(f"è°ƒè¯•: å‰500å­—ç¬¦ä¸­æœ‰ {non_printable_count} ä¸ªä¸å¯æ‰“å°å­—ç¬¦")
                # æ˜¾ç¤ºéæ‰“å°å­—ç¬¦çš„ä½ç½®
                for i, c in enumerate(display_text[:500]):
                    if c not in printable:
                        st.write(f"è°ƒè¯•: ä½ç½® {i} çš„å­—ç¬¦: repr={repr(c)}, ord={ord(c)}")
            # æ˜¾ç¤ºå‰200å­—ç¬¦
            st.code(display_text[:200] if display_text else 'ç©º', language='text')
            # æ˜¾ç¤ºreprï¼ŒæŸ¥çœ‹éšè—å­—ç¬¦
            st.write(f"è°ƒè¯•: display_textå‰200å­—ç¬¦çš„repr: {repr(display_text[:200])}")

    def update_final_preview():
        """æ›´æ–°æœ€ç»ˆé¢„è§ˆæ–‡æœ¬çš„å›è°ƒå‡½æ•°"""
        new_value = st.session_state.get('final_preview_text_display', '')
        logger.info(f"=== æ–‡æœ¬åŒºåŸŸon_changeå›è°ƒè¢«è°ƒç”¨ ===")
        logger.info(f"new_valueé•¿åº¦: {len(new_value)}")
        logger.info(f"new_valueç±»å‹: {type(new_value)}")
        if new_value:
            logger.debug(f"new_valueå‰100å­—ç¬¦: {new_value[:100]}")

        # è·å–å½“å‰çš„æ¸…ç†ç‰ˆæœ¬
        current_cleaned = st.session_state.get('final_preview_text_cleaned', '')
        logger.info(f"å½“å‰final_preview_text_cleanedé•¿åº¦: {len(current_cleaned)}")

        # æ£€æŸ¥æ–°å€¼æ˜¯å¦ä¸æ¸…ç†ç‰ˆæœ¬ç›¸åŒï¼ˆå¯èƒ½æ˜¯AIå¤„ç†åçš„è‡ªåŠ¨æ›´æ–°ï¼‰
        is_same_as_cleaned = new_value == current_cleaned
        logger.info(f"æ–°å€¼ä¸æ¸…ç†ç‰ˆæœ¬ç›¸åŒ: {is_same_as_cleaned}")

        original_length = len(st.session_state.get('final_preview_text', ''))
        logger.info(f"åŸfinal_preview_texté•¿åº¦: {original_length}")

        if new_value:
            st.session_state['final_preview_text'] = new_value
            logger.info(f"æ›´æ–°final_preview_textï¼Œæ–°é•¿åº¦: {len(new_value)}")
        else:
            logger.warning(f"new_valueä¸ºç©ºæˆ–Noneï¼Œä¸æ›´æ–°final_preview_text")

        # åªæœ‰åœ¨æ–°å€¼ä¸æ¸…ç†ç‰ˆæœ¬ä¸åŒæ—¶æ‰æ¸…é™¤æ¸…ç†ç‰ˆæœ¬ï¼ˆè¡¨ç¤ºç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘ï¼‰
        if not is_same_as_cleaned and current_cleaned:
            st.session_state['final_preview_text_cleaned'] = ''
            logger.info("ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘æ–‡æœ¬ï¼Œå·²æ¸…ç©ºfinal_preview_text_cleaned")
        else:
            logger.info("æ–‡æœ¬æœªå˜åŒ–æˆ–ä¸æ¸…ç†ç‰ˆæœ¬ç›¸åŒï¼Œä¿ç•™final_preview_text_cleaned")

    # ç¡®ä¿display_textæ˜¯å­—ç¬¦ä¸²
    text_area_value = str(display_text) if display_text is not None else ""

    logger.info(f"=== æ–‡æœ¬åŒºåŸŸæ¸²æŸ“ä¿¡æ¯ ===")
    logger.info(f"display_textç±»å‹: {type(display_text)}")
    logger.info(f"display_texté•¿åº¦: {len(display_text) if display_text else 0}")
    logger.info(f"text_area_valueç±»å‹: {type(text_area_value)}")
    logger.info(f"text_area_valueé•¿åº¦: {len(text_area_value)}")
    logger.debug(f"text_area_valueå‰200å­—ç¬¦: {text_area_value[:200] if text_area_value else 'ç©º'}")
    logger.info(f"final_preview_text_cleanedå­˜åœ¨: {'final_preview_text_cleaned' in st.session_state}")
    logger.info(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
    logger.info(f"final_preview_text_display session stateå­˜åœ¨: {'final_preview_text_display' in st.session_state}")

    # åœ¨ä¸»ç•Œé¢æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    if DEBUG_MODE:
        st.markdown("---")
        st.markdown("**æ–‡æœ¬åŒºåŸŸè°ƒè¯•ä¿¡æ¯:**")
        col_debug1, col_debug2 = st.columns(2)
        with col_debug1:
            st.write(f"display_texté•¿åº¦: {len(display_text) if display_text else 0}")
            st.write(f"text_area_valueé•¿åº¦: {len(text_area_value)}")
            st.write(f"final_preview_texté•¿åº¦: {len(st.session_state['final_preview_text'])}")
        with col_debug2:
            st.write(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
            st.write(f"final_preview_text_display session stateå­˜åœ¨: {'final_preview_text_display' in st.session_state}")

        # æ˜¾ç¤ºtext_area_valueçš„å‰100å­—ç¬¦
        if text_area_value and len(text_area_value) > 0:
            st.text_area("text_area_valueé¢„è§ˆ", value=text_area_value[:300], height=150, key="debug_preview", disabled=True)
            # æ˜¾ç¤ºreprç‰ˆæœ¬ï¼ŒæŸ¥çœ‹éšè—å­—ç¬¦
            st.write(f"text_area_valueå‰200å­—ç¬¦repr: {repr(text_area_value[:200])}")
            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«ç©ºç™½å­—ç¬¦
            if text_area_value.strip() == "":
                st.error("text_area_valueåªåŒ…å«ç©ºç™½å­—ç¬¦ï¼")
                # æ˜¾ç¤ºå­—ç¬¦ç»Ÿè®¡
                import string
                printable = set(string.printable)
                non_printable = sum(1 for c in text_area_value[:500] if c not in printable)
                st.write(f"å‰500å­—ç¬¦ä¸­ä¸å¯æ‰“å°å­—ç¬¦æ•°: {non_printable}")
        else:
            st.warning("text_area_valueä¸ºç©º")
        st.markdown("---")

    st.text_area(
        "æœ€ç»ˆæ–‡æœ¬é¢„è§ˆ",
        value=text_area_value,
        height=500,
        key="final_preview_text_display",
        on_change=update_final_preview
    )

    # è°ƒè¯•ï¼šæ£€æŸ¥æ–‡æœ¬åŒºåŸŸæ¸²æŸ“åçš„çŠ¶æ€
    if DEBUG_MODE:
        st.write(f"è°ƒè¯•: æ–‡æœ¬åŒºåŸŸæ¸²æŸ“åï¼Œfinal_preview_text_display session stateé•¿åº¦: {len(st.session_state.get('final_preview_text_display', ''))}")
        st.write(f"è°ƒè¯•: æ–‡æœ¬åŒºåŸŸæ¸²æŸ“åï¼Œfinal_preview_texté•¿åº¦: {len(st.session_state.get('final_preview_text', ''))}")
        # å°è¯•ç”¨markdownæ˜¾ç¤ºä¸€å°æ®µå†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦æ¸²æŸ“é—®é¢˜
        if display_text and len(display_text) > 50:
            st.markdown(f"**ç›´æ¥Markdownæ˜¾ç¤ºå‰100å­—ç¬¦:** {display_text[:100]}...")

    # å»é™¤AIè¯æ±‡æŒ‰é’®
    st.divider()
    st.markdown("#### å»é™¤AIå†™ä½œé«˜é¢‘è¯æ±‡")
    st.caption("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å»é™¤æ–‡æœ¬ä¸­çš„AIå†™ä½œé«˜é¢‘è¯æ±‡å’Œå¥å¼ï¼ˆé»‘åå•ï¼‰ã€‚")

    # åœ¨å»é™¤AIè¯æ±‡æŒ‰é’®å‰æ·»åŠ è°ƒè¯•ä»£ç 
    if DEBUG_MODE:
        st.write(f"è°ƒè¯•: final_preview_texté•¿åº¦ = {len(st.session_state['final_preview_text'])}")
        st.write(f"è°ƒè¯•: confirmed_paragraphs = {st.session_state['confirmed_paragraphs']}")
        st.write(f"è°ƒè¯•: confirmed_contents keys = {list(st.session_state['confirmed_contents'].keys())}")

    if api_key:
        if st.button("ğŸš« å»é™¤AIè¯æ±‡å¹¶ç”Ÿæˆæœ€ç»ˆç‰ˆ", type="secondary", use_container_width=True):
            logger.info(f"=== ç‚¹å‡»å»é™¤AIè¯æ±‡æŒ‰é’® ===")
            logger.info(f"final_preview_texté•¿åº¦: {len(st.session_state['final_preview_text'])}")
            logger.info(f"final_preview_textå‰200å­—ç¬¦: {st.session_state['final_preview_text'][:200] if st.session_state['final_preview_text'] else 'ç©º'}")
            logger.info(f"final_preview_text_cleanedé•¿åº¦: {len(st.session_state.get('final_preview_text_cleaned', ''))}")
            logger.info(f"final_preview_text_cleanedå‰200å­—ç¬¦: {st.session_state.get('final_preview_text_cleaned', '')[:200] if st.session_state.get('final_preview_text_cleaned') else 'ç©º'}")
            logger.info(f"final_preview_text_display session stateå­˜åœ¨: {'final_preview_text_display' in st.session_state}")
            if 'final_preview_text_display' in st.session_state:
                logger.info(f"final_preview_text_displayé•¿åº¦: {len(st.session_state['final_preview_text_display'])}")
                logger.info(f"final_preview_text_displayå‰200å­—ç¬¦: {st.session_state['final_preview_text_display'][:200] if st.session_state['final_preview_text_display'] else 'ç©º'}")
            logger.info(f"confirmed_paragraphs: {st.session_state['confirmed_paragraphs']}")
            logger.info(f"confirmed_contents keys: {list(st.session_state['confirmed_contents'].keys())}")

            with st.spinner("æ­£åœ¨å»é™¤AIå†™ä½œé«˜é¢‘è¯æ±‡..."):
                try:
                    # è·å–å½“å‰æ–‡æœ¬ - ä¼˜å…ˆä½¿ç”¨æ–‡æœ¬åŒºåŸŸçš„å½“å‰å†…å®¹
                    current_text = st.session_state.get('final_preview_text_display', st.session_state['final_preview_text'])
                    logger.info(f"å‡†å¤‡å¤„ç†çš„æ–‡æœ¬æ¥æº: {'final_preview_text_display' if 'final_preview_text_display' in st.session_state else 'final_preview_text'}")
                    logger.info(f"å‡†å¤‡å¤„ç†çš„æ–‡æœ¬é•¿åº¦: {len(current_text) if current_text else 0}")
                    logger.info(f"å‡†å¤‡å¤„ç†çš„æ–‡æœ¬å‰200å­—ç¬¦: {current_text[:200] if current_text else 'ç©º'}")

                    if not current_text.strip():
                        logger.warning("æœ€ç»ˆé¢„è§ˆæ–‡æœ¬ä¸ºç©º")
                        st.warning("æœ€ç»ˆé¢„è§ˆæ–‡æœ¬ä¸ºç©º")
                    else:
                        logger.info(f"è°ƒç”¨AIæ¨¡å‹å¤„ç†æ–‡æœ¬ï¼Œé•¿åº¦: {len(current_text)}")
                        logger.info(f"æ„å»ºpromptå¹¶å‘é€åˆ°AI...")
                        # åˆå§‹åŒ–æ¨¡å‹
                        refine_model = genai.GenerativeModel(model_name)
                        res = refine_model.generate_content(
                            build_remove_ai_vocab_prompt(current_text),
                            safety_settings=safety_settings_interactive
                        )
                        # è·å–å¤„ç†åçš„æ–‡æœ¬
                        cleaned_text = res.text
                        logger.info(f"AIå¤„ç†å®Œæˆï¼Œè¿”å›æ–‡æœ¬é•¿åº¦: {len(cleaned_text)}")
                        logger.debug(f"å¤„ç†åæ–‡æœ¬å‰500å­—ç¬¦: {cleaned_text[:500] if cleaned_text else 'ç©º'}")
                        logger.info(f"åŸå§‹æ–‡æœ¬é•¿åº¦: {len(current_text)}ï¼Œå¤„ç†åé•¿åº¦: {len(cleaned_text)}")

                        # æ›´æ–°ä¼šè¯çŠ¶æ€ - ä¿å­˜æ¸…ç†ç‰ˆæœ¬ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬
                        st.session_state['final_preview_text_cleaned'] = cleaned_text
                        logger.info(f"final_preview_text_cleaned å·²è®¾ç½®ï¼Œé•¿åº¦: {len(cleaned_text)}")
                        logger.info(f"session stateä¸­ final_preview_text_cleaned ç°åœ¨: {len(st.session_state.get('final_preview_text_cleaned', ''))} å­—ç¬¦")

                        # æ¸…é™¤æ–‡æœ¬åŒºåŸŸçš„session stateï¼Œç¡®ä¿ä¸‹æ¬¡æ¸²æŸ“ä½¿ç”¨æ–°å€¼
                        if 'final_preview_text_display' in st.session_state:
                            del st.session_state['final_preview_text_display']
                            logger.info("å·²æ¸…é™¤final_preview_text_displayï¼Œç¡®ä¿ä¸‹æ¬¡æ¸²æŸ“ä½¿ç”¨æ¸…ç†ç‰ˆæœ¬")

                        # æ³¨æ„ï¼šæ–‡æœ¬åŒºåŸŸçš„å€¼ä¼šåœ¨ä¸‹ä¸€æ¬¡æ¸²æŸ“æ—¶é€šè¿‡text_area_valueè‡ªåŠ¨æ›´æ–°
                        logger.info(f"æ¸…ç†ç‰ˆæœ¬å·²ä¿å­˜åˆ°final_preview_text_cleaned")

                        # æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬æ˜¯å¦åŒ…å«Markdownç¬¦å·
                        markdown_symbols = ['**', '*', '__', '_', '`', '#', '##', '###', '####']
                        found_symbols = [sym for sym in markdown_symbols if sym in cleaned_text]
                        if found_symbols:
                            logger.warning(f"æ¸…ç†æ–‡æœ¬ä¸­ä»ç„¶åŒ…å«Markdownç¬¦å·: {found_symbols}")

                        # è°ƒè¯•ï¼šæ£€æŸ¥ final_preview_text æ˜¯å¦è¢«æ„å¤–ä¿®æ”¹
                        logger.info(f"å¤„ç†å final_preview_texté•¿åº¦: {len(st.session_state['final_preview_text'])}")

                        # ç«‹å³è®°å½•æœ€ç»ˆæ˜¾ç¤ºæ–‡æœ¬çš„çŠ¶æ€
                        cleaned_text_check = st.session_state.get('final_preview_text_cleaned', '')
                        if cleaned_text_check and cleaned_text_check.strip():
                            display_text_should_be = cleaned_text_check
                            logger.info(f"å¤„ç†å®Œæˆåï¼Œdisplay_textåº”è¯¥æ˜¾ç¤ºfinal_preview_text_cleanedï¼Œé•¿åº¦: {len(display_text_should_be)}")
                        else:
                            display_text_should_be = st.session_state['final_preview_text']
                            logger.info(f"å¤„ç†å®Œæˆåï¼Œdisplay_textåº”è¯¥æ˜¾ç¤ºfinal_preview_textï¼Œé•¿åº¦: {len(display_text_should_be)}")

                        st.success("AIè¯æ±‡å·²å»é™¤ï¼Œæ¸…ç†ç‰ˆæœ¬å·²ç”Ÿæˆå¹¶æ˜¾ç¤ºåœ¨æ–‡æœ¬åŒºåŸŸä¸­ï¼")
                        st.rerun()
                except Exception as e:
                    logger.error(f"å»é™¤AIè¯æ±‡å¤±è´¥: {e}")
                    logger.exception(f"å®Œæ•´å¼‚å¸¸ä¿¡æ¯:")
                    st.error(f"å¤„ç†å¤±è´¥: {e}")
    else:
        st.warning("è¯·å…ˆé…ç½®API Keyä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
    
    if HAS_DOCX:
        # å‡†å¤‡å¯¼å‡ºæ–‡æœ¬ - ä¼˜å…ˆä½¿ç”¨æ¸…ç†ç‰ˆæœ¬
        export_text = st.session_state.get('final_preview_text_cleaned') or st.session_state['final_preview_text']
        if not keep_highlight:
            export_text = remove_markdown_bold(export_text)
        
        # åˆ›å»ºWordæ–‡æ¡£
        docx_file = create_docx_smart(export_text, custom_header)
        
        # æ·»åŠ ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ä¸‹è½½Wordæ–‡æ¡£",
            data=docx_file,
            file_name=f"Personal_Statement_{target_school.replace(' ', '_') if target_school else 'Final'}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            type="primary",
            use_container_width=True
        )
        
