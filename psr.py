import os
import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import time
from io import BytesIO
from PIL import Image

# ==========================================
# ğŸ”´ ç½‘ç»œä»£ç†é…ç½®
# è®¾ç½®HTTPå’ŒHTTPSä»£ç†ï¼Œç”¨äºç¡®ä¿åº”ç”¨èƒ½å¤Ÿé€šè¿‡ä»£ç†è®¿é—®Google Gemini API
# ==========================================
# os.environ["HTTP_PROXY"] = "http://127.0.0.1:7897"
# os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7897"

# ==========================================
# ä¾èµ–åº“æ£€æµ‹ä¸åˆå§‹åŒ–
# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†å¤„ç†Wordæ–‡æ¡£å’ŒPDFæ–‡ä»¶çš„åº“ï¼Œå¹¶ç›¸åº”è®¾ç½®æ ‡å¿—
# ==========================================
HAS_DOCX = False
HAS_PDF = False

try:
    # å°è¯•å¯¼å…¥å¤„ç†Wordæ–‡æ¡£çš„åº“
    from docx import Document
    from docx.shared import Pt, Inches
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.enum.section import WD_SECTION
    HAS_DOCX = True
except ImportError:
    pass

try:
    # å°è¯•å¯¼å…¥å¤„ç†PDFæ–‡ä»¶çš„åº“
    import pypdf
    HAS_PDF = True
except ImportError:
    pass

# ==========================================
# è‡ªå®šä¹‰UIæ ·å¼å‡½æ•°
# é€šè¿‡æ³¨å…¥CSSæ¥åˆ›å»ºç±³è‰²èƒŒæ™¯å’Œå®è“è‰²æŒ‰é’®çš„è‡ªå®šä¹‰ç•Œé¢
# ==========================================
def apply_custom_css():
    st.markdown("""
    <style>
    /* å¼•å…¥ Inter å­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    
    /* å…¨å±€å˜é‡ - å®šåˆ¶é…è‰² */
    :root {
        --primary-color: #3666FA; /* å®è“ RGB 54, 102, 250 */
        --bg-color: #FBF7EC;      /* ç±³è‰² RGB 251, 247, 236 */
        --text-color: #3666FA;    /* å­—ä½“é¢œè‰²è·Ÿéšä¸»è‰² */
        --button-text: #FBF7EC;   /* æŒ‰é’®å†…æ–‡å­—é¢œè‰² (ç±³è‰²) */
    }

    /* åŸºç¡€é‡ç½® */
    html, body, [class*="css"] {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
        color: var(--text-color);
        background-color: var(--bg-color);
    }
    
    /* éšè— Streamlit é»˜è®¤ Header å’Œ Footer */
    header {visibility: hidden;}
    footer {visibility: hidden;}

    /* ä¸»å®¹å™¨èƒŒæ™¯ä¼˜åŒ– */
    .stApp {
        background-color: var(--bg-color);
    }

    /* ä¾§è¾¹æ ä¼˜åŒ– - æ·±è‰²æ²‰æµ¸å¼ */
    [data-testid="stSidebar"] {
        background-color: #0f172a; 
        border-right: 1px solid #1e293b;
    }
    
    [data-testid="stSidebar"] h2, 
    [data-testid="stSidebar"] h3, 
    [data-testid="stSidebar"] label,
    [data-testid="stSidebar"] p,
    [data-testid="stSidebar"] .stMarkdown,
    [data-testid="stSidebar"] div {
        color: #e2e8f0 !important;
    }
    
    [data-testid="stSidebar"] hr {
        border-color: #334155 !important;
    }

    /* æ ‡é¢˜æ ·å¼ - å·¦å¯¹é½ï¼Œå¤§å­—ä½“ */
    h1 {
        color: var(--text-color) !important;
        font-weight: 800 !important;
        font-size: 2.5rem !important;
        letter-spacing: -0.02em;
        margin-bottom: 2rem !important;
        text-align: left !important;
    }
    
    /* å°æ ‡é¢˜æ ·å¼ */
    h2, h3 {
        color: var(--text-color) !important;
        font-weight: 600 !important;
        margin-top: 1rem !important;
        margin-bottom: 1rem !important;
    }
    
    /* æ™®é€šæ–‡æœ¬å’ŒLabelé¢œè‰² */
    p, label, .stMarkdown, .stText {
        color: var(--text-color) !important;
    }

    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] {
        border: none !important;
        border-radius: 8px !important;
        padding: 0.6rem 0.8rem !important;
        background-color: #ffffff !important;
        font-size: 0.95rem !important;
        color: #1e293b !important; /* è¾“å…¥æ¡†å†…éƒ¨æ–‡å­—æ·±è‰² */
        transition: all 0.2s ease;
    }

    .stTextInput input:focus, .stTextArea textarea:focus {
        border-color: var(--primary-color) !important;
        box-shadow: 0 0 0 2px rgba(54, 102, 250, 0.1) !important;
    }

    /* æŒ‰é’®ç¾åŒ– - å®è“èƒŒæ™¯ï¼Œç±³è‰²æ–‡å­— */
    .stButton button {
        background-color: var(--primary-color) !important;
        color: var(--button-text) !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.6rem 1.5rem !important;
        font-weight: 500 !important;
        font-size: 0.95rem !important;
        box-shadow: 0 1px 2px rgba(54, 102, 250, 0.2) !important;
        transition: all 0.2s ease !important;
    }
    
    /* å¼ºåˆ¶æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ é¢œè‰²ä¸ºç±³è‰² */
    .stButton button * {
        color: var(--button-text) !important;
    }

    .stButton button:hover {
        opacity: 0.9;
        transform: translateY(-1px);
    }
    
    /* ä¸‹è½½æŒ‰é’® */
    .stDownloadButton button {
        background-color: var(--primary-color) !important;
        color: #FFFFFF !important; /* ä¿®æ”¹ä¸ºç™½è‰²æ–‡å­— */
        border: none !important;
    }
                
    /* å¼ºåˆ¶ä¸‹è½½æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ é¢œè‰²ä¸€è‡´ */
    .stDownloadButton button * {
        color: #FFFFFF !important; /* ç¡®ä¿æŒ‰é’®å†…æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç™½è‰² */            
    }
                
    .stDownloadButton button:hover {
        opacity: 0.9;
    }

    /* Expander æ ·å¼å¾®è°ƒ - å¢åŠ å­—é‡ä»¥æ”¯æŒåŠ ç²—æ•ˆæœ */
    .streamlit-expanderHeader {
        background-color: #ffffff !important;
        border: 1px solid rgba(54, 102, 250, 0.2) !important;
        border-radius: 8px !important;
        color: var(--text-color) !important;
        font-weight: 600 !important; /* å¼ºåˆ¶åŠ ç²— */
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    [data-testid="stFileUploader"] {
        border: 1px dashed rgba(54, 102, 250, 0.4);
        background-color: #ffffff;
        border-radius: 8px;
        padding: 1rem;
        min-height: 150px; /* ç¡®ä¿ä¸æ–‡æœ¬æ¡†é«˜åº¦ä¸€è‡´ */
        display: flex;
        flex-direction: column;
        justify-content: center;
    }
    [data-testid="stFileUploader"]:hover {
        border-color: var(--primary-color);
        background-color: rgba(54, 102, 250, 0.05);
    }

    /* å¸ƒå±€é—´è·è°ƒæ•´ */
    .block-container {
        padding-top: 3rem !important;
        padding-bottom: 3rem !important;
        max-width: 1200px !important;
    }
    
    /* åˆ†å‰²çº¿é¢œè‰² */
    hr {
        border-color: rgba(54, 102, 250, 0.2) !important;
    }
    
    /* è¿›åº¦æ¡é¢œè‰² */
    .stProgress > div > div > div > div {
        background-color: var(--primary-color) !important;
    }
    
    /* æ·»åŠ é«˜äº®æ ·å¼ */
    .highlight {
        background-color: #FFEB3B;
        font-weight: bold;
    }
    
    /* ç»Ÿä¸€æ–‡æœ¬æ¡†æ ·å¼ */
    .stTextArea textarea {
        border: 1px solid rgba(54, 102, 250, 0.2) !important;
        border-radius: 8px !important;
        padding: 10px !important;
        font-family: 'Times New Roman', serif !important;
        font-size: 14px !important;
        line-height: 1.5 !important;
        color: #333333 !important;
        background-color: #ffffff !important;
        height: 300px !important;  /* ç»Ÿä¸€é«˜åº¦ */
    }
    
    /* é¢„è§ˆå®¹å™¨æ ·å¼ */
    .preview-container {
        border: 1px solid rgba(54, 102, 250, 0.2);
        border-radius: 8px;
        padding: 10px;
        background-color: #ffffff;
        height: 300px;
        overflow-y: auto;
        margin-top: 10px; /* ä¸æ–‡æœ¬åŒºåŸŸå¯¹é½ */
        font-family: 'Times New Roman', serif;
        font-size: 14px;
        line-height: 1.5;
        color: #333;
    }
    
    /* æ‰¹æ³¨ç»“æœé¢„è§ˆå®¹å™¨ */
    .annotation-result-container {
        border: 1px solid rgba(54, 102, 250, 0.2);
        border-radius: 8px;
        padding: 10px;
        background-color: #ffffff;
        height: 300px;
        overflow-y: auto;
        margin-top: 10px;
        margin-bottom: 20px;
        font-family: 'Times New Roman', serif;
        font-size: 14px;
        line-height: 1.5;
        color: #333;
    }
    
    /* é¢„è§ˆæ ‡é¢˜æ ·å¼ */
    .preview-title {
        color: #3666FA;
        margin-bottom: 10px;
        font-weight: bold;
        font-size: 14px;
    }
    
    /* é¢„è§ˆæ–‡æœ¬æ ·å¼ */
    .preview-text {
        font-family: 'Times New Roman', serif;
        font-size: 14px;
        line-height: 1.5;
        color: #333;
    }
    
    /* ç»Ÿä¸€ä¿¡æ¯æ¡†æ ·å¼ */
    .stAlert {
        border-radius: 8px !important;
    }
    
    /* è°ƒæ•´åˆ—é—´è· */
    [data-testid="column"] {
        padding: 0 10px !important;
    }
    
    /* ç¡®ä¿é¢„è§ˆåŒºåŸŸä¸æ–‡æœ¬æ¡†å¯¹é½ */
    .preview-wrapper {
        height: 100%;
        display: flex;
        flex-direction: column;
    }
    
    /* ä¿®æ”¹éƒ¨åˆ†é«˜äº®æ˜¾ç¤º */
    .modified-text {
        background-color: #FFEB3B;
        font-weight: bold;
    }
    
    /* ç¡®ä¿ä¸Šä¼ æ–‡ä»¶åŒºåŸŸå’Œæ–‡æœ¬æ¡†é¡¶ç«¯å¯¹é½ */
    .top-align-container {
        display: flex;
        align-items: flex-start;
    }
    
    /* ç§»é™¤ä¸Šä¼ æ–‡ä»¶åŒºåŸŸçš„ä¸Šè¾¹è· */
    .top-align-container [data-testid="stFileUploader"] {
        margin-top: 0 !important;
    }
    
    /* ç§»é™¤æ–‡æœ¬åŒºåŸŸçš„ä¸Šè¾¹è· */
    .top-align-container .stTextArea {
        margin-top: 0 !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# é¡µé¢é…ç½®ä¸ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
# è®¾ç½®é¡µé¢æ ‡é¢˜ã€å¸ƒå±€å’Œåˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ä¼šè¯çŠ¶æ€å˜é‡
# ==========================================
st.set_page_config(page_title="ä¸ªäººé™ˆè¿°ä¿®æ”¹", layout="wide")

# åº”ç”¨è‡ªå®šä¹‰UIæ ·å¼
apply_custom_css()

# åˆå§‹åŒ–æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡ï¼Œç”¨äºåœ¨é¡µé¢é‡æ–°åŠ è½½æ—¶ä¿æŒæ•°æ®
if 'ps_content' not in st.session_state: st.session_state['ps_content'] = ""  # åŸå§‹PSå†…å®¹
if 'curr_content' not in st.session_state: st.session_state['curr_content'] = ""  # è¯¾ç¨‹å†…å®¹
if 'strategy_content' not in st.session_state: st.session_state['strategy_content'] = ""  # ç­–ç•¥å†…å®¹
if 'sections_data' not in st.session_state: st.session_state['sections_data'] = []  # æ®µè½æ•°æ®
if 'translation_results' not in st.session_state: st.session_state['translation_results'] = {}  # ç¿»è¯‘ç»“æœ
if 'edited_translations' not in st.session_state: st.session_state['edited_translations'] = {}  # ç¼–è¾‘åçš„ç¿»è¯‘
if 'refine_results' not in st.session_state: st.session_state['refine_results'] = {}  # ä¿®æ”¹ç»“æœ
if 'preview_results' not in st.session_state: st.session_state['preview_results'] = {}  # é¢„è§ˆç»“æœ
if 'generation_complete' not in st.session_state: st.session_state['generation_complete'] = False  # ç”Ÿæˆå®Œæˆæ ‡å¿—
if 'full_response' not in st.session_state: st.session_state['full_response'] = ""  # å®Œæ•´å“åº”
if 'show_sections' not in st.session_state: st.session_state['show_sections'] = False  # æ˜¾ç¤ºæ®µè½æ ‡å¿—
if 'annotation_processing' not in st.session_state: st.session_state['annotation_processing'] = {}  # æ‰¹æ³¨å¤„ç†çŠ¶æ€
if 'annotation_results' not in st.session_state: st.session_state['annotation_results'] = {}  # æ‰¹æ³¨å¤„ç†ç»“æœ
if 'original_texts' not in st.session_state: st.session_state['original_texts'] = {}  # åŸå§‹æ–‡æœ¬ï¼Œç”¨äºæ¯”è¾ƒ
if 'final_preview_text' not in st.session_state: st.session_state['final_preview_text'] = ""  # æœ€ç»ˆé¢„è§ˆæ–‡æœ¬
if 'confirmed_paragraphs' not in st.session_state: st.session_state['confirmed_paragraphs'] = set()  # å·²ç¡®è®¤æ®µè½çš„ç´¢å¼•

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.markdown("### è®¾ç½®")
    api_key = st.text_input("Google Gemini API Key", type="password")
    
    # å¦‚æœæä¾›äº†APIå¯†é’¥ï¼Œåˆ™é…ç½®Google Geminiå®¢æˆ·ç«¯
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)
    
    # æ˜¾ç¤ºå·²ç”Ÿæˆæ®µè½çš„æ•°é‡
    if st.session_state['sections_data']:
        st.divider()
        st.success(f"å½“å‰å·²ç”Ÿæˆ {len(st.session_state['sections_data'])} ä¸ªæ®µè½")

# è®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹
model_name = "gemini-2.5-pro"

# ==========================================
# å·¥å…·å‡½æ•°
# åŒ…å«å„ç§è¾…åŠ©åŠŸèƒ½ï¼Œå¦‚æ–‡ä»¶å¤„ç†ã€æ–‡æœ¬æ¸…ç†å’Œæ ¼å¼è½¬æ¢
# ==========================================

# ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
def extract_text_from_file(uploaded_file):
    """ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬ï¼Œæ”¯æŒDOCXã€PDFå’ŒTXTæ ¼å¼"""
    if not uploaded_file: return ""
    file_type = uploaded_file.name.split('.')[-1].lower()
    text = ""
    try:
        if file_type == 'docx' and HAS_DOCX:
            doc = Document(uploaded_file)
            for para in doc.paragraphs: text += para.text + "\n"
        elif file_type == 'pdf' and HAS_PDF:
            reader = pypdf.PdfReader(uploaded_file)
            for page in reader.pages: text += page.extract_text() + "\n"
        elif file_type == 'txt':
            text = uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        return f"[è¯»å–æ–‡ä»¶å‡ºé”™: {e}]"
    return text

# æ¸…é™¤æ–‡æœ¬ä¸­çš„æ˜Ÿå·
def clean_asterisks(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„æ‰€æœ‰æ˜Ÿå·å­—ç¬¦"""
    if not text: return ""
    return text.replace("*", "")

# ç§»é™¤MarkdownåŠ ç²—æ ‡è®°
def remove_markdown_bold(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„MarkdownåŠ ç²—æ ‡è®°ï¼ˆ**ï¼‰"""
    return text.replace("**", "")

# è¿‡æ»¤AIç”Ÿæˆå†…å®¹ä¸­çš„é—®å€™è¯­
def filter_ai_greeting(text):
    """ç§»é™¤AIç”Ÿæˆå†…å®¹å¼€å¤´çš„å¸¸è§é—®å€™è¯­å’Œä»‹ç»è¯­"""
    greeting_patterns = [
        r'^å¥½çš„ï¼Œä½œä¸º.*?é¡¾é—®.*?\n+',
        r'^ä½œä¸º.*?é¡¾é—®.*?\n+',
        r'^æˆ‘å°†.*?åˆ†æ.*?\n+',
        r'^ä¸‹é¢æˆ‘å°†.*?\n+',
        r'^æˆ‘ä¼š.*?å¸®åŠ©æ‚¨.*?\n+',
        r'^è®©æˆ‘.*?ä¸ºæ‚¨.*?\n+'
    ]
    
    for pattern in greeting_patterns:
        text = re.sub(pattern, '', text, flags=re.DOTALL)
    
    return text

# åˆ›å»ºå¸¦æœ‰æ ¼å¼çš„Wordæ–‡æ¡£
def create_docx_smart(text_content, major_name=""):
    """åˆ›å»ºæ ¼å¼åŒ–çš„Wordæ–‡æ¡£ï¼ŒåŒ…æ‹¬é¡µçœ‰ã€å­—ä½“è®¾ç½®å’ŒåŠ ç²—é«˜äº®"""
    if not HAS_DOCX: return None
    doc = Document()
    
    # è®¾ç½®é¡µé¢è¾¹è·
    sections = doc.sections
    for section in sections:
        section.top_margin = Inches(1)
        section.bottom_margin = Inches(1)
        section.left_margin = Inches(1)
        section.right_margin = Inches(1)
    
    # æ·»åŠ é¡µçœ‰
    header_text = f"Personal Statement - {major_name}" if major_name else "Personal Statement"
    header = doc.sections[0].header
    header_para = header.paragraphs[0]
    header_para.text = header_text
    header_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # è®¾ç½®é¡µçœ‰æ–‡æœ¬æ ¼å¼
    header_run = header_para.runs[0]
    header_run.font.name = 'Times New Roman'
    header_run.font.size = Pt(11)
    
    # è®¾ç½®æ­£æ–‡é»˜è®¤æ ·å¼
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Times New Roman'
    font.size = Pt(11)
    
    # å¤„ç†æ­£æ–‡å†…å®¹ï¼Œä¿ç•™åŠ ç²—æ ¼å¼
    lines = text_content.split('\n')
    for line in lines:
        if not line.strip(): continue
        clean_line = line.replace('[[LOGIC]]', '').replace('[[DRAFT]]', '')
        p = doc.add_paragraph()
        parts = re.split(r'(\*\*.*?\*\*)', clean_line)
        for part in parts:
            if part.startswith('**') and part.endswith('**'):
                clean_text = part[2:-2]
                run = p.add_run(clean_text)
                run.bold = True
            else:
                p.add_run(part)
    
    # å°†æ–‡æ¡£ä¿å­˜åˆ°å†…å­˜ç¼“å†²åŒº
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ç”ŸæˆHTMLé¢„è§ˆï¼Œé«˜äº®æ˜¾ç¤ºåŠ ç²—éƒ¨åˆ†
def generate_preview_html(text_with_markdown):
    """å°†Markdownæ ¼å¼çš„æ–‡æœ¬è½¬æ¢ä¸ºHTMLé¢„è§ˆï¼Œé«˜äº®æ˜¾ç¤ºåŠ ç²—éƒ¨åˆ†"""
    # æ›¿æ¢markdownåŠ ç²—è¯­æ³•ä¸ºHTML spanæ ‡ç­¾
    html_text = re.sub(r'\*\*(.*?)\*\*', r'<span style="background-color: #FFEB3B; font-weight: bold;">\1</span>', text_with_markdown)
    
    # æ·»åŠ HTMLæ ·å¼ï¼Œç¡®ä¿ä¸æ–‡æœ¬æ¡†æ ·å¼ä¸€è‡´
    styled_html = f"""
    <div class="preview-container">
        <div class="preview-text">
            {html_text}
        </div>
    </div>
    """
    return styled_html

# æ–°å¢å‡½æ•°ï¼šæ¯”è¾ƒæ–‡æœ¬å¹¶é«˜äº®å·®å¼‚éƒ¨åˆ†
def highlight_differences(original_text, new_text):
    """æ¯”è¾ƒåŸå§‹æ–‡æœ¬å’Œæ–°æ–‡æœ¬ï¼Œé«˜äº®æ˜¾ç¤ºå·®å¼‚éƒ¨åˆ†"""
    # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…ä¸Šéœ€è¦æ›´å¤æ‚çš„æ–‡æœ¬å·®å¼‚æ¯”è¾ƒç®—æ³•
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼šå°†æ–°æ–‡æœ¬ä¸­çš„æ¯ä¸ªå¥å­ä¸åŸæ–‡æœ¬æ¯”è¾ƒ
    
    # å¦‚æœåŸæ–‡æœ¬ä¸ºç©ºï¼Œåˆ™å°†æ•´ä¸ªæ–°æ–‡æœ¬é«˜äº®æ˜¾ç¤º
    if not original_text:
        return f"<span class='modified-text'>{new_text}</span>"
    
    # å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­
    def split_into_sentences(text):
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å¥å­ï¼Œè€ƒè™‘å„ç§æ ‡ç‚¹ç¬¦å·
        return re.split(r'([.!?ã€‚ï¼ï¼Ÿ\n]+)', text)
    
    orig_sentences = split_into_sentences(original_text)
    new_sentences = split_into_sentences(new_text)
    
    # åˆå¹¶ç›¸é‚»çš„åˆ†å‰²ç»“æœ
    orig_sentences_merged = []
    for i in range(0, len(orig_sentences)-1, 2):
        if i+1 < len(orig_sentences):
            orig_sentences_merged.append(orig_sentences[i] + orig_sentences[i+1])
        else:
            orig_sentences_merged.append(orig_sentences[i])
    
    new_sentences_merged = []
    for i in range(0, len(new_sentences)-1, 2):
        if i+1 < len(new_sentences):
            new_sentences_merged.append(new_sentences[i] + new_sentences[i+1])
        else:
            new_sentences_merged.append(new_sentences[i])
    
    # æ ‡è®°æ¯ä¸ªæ–°å¥å­æ˜¯å¦å­˜åœ¨äºåŸæ–‡æœ¬ä¸­
    result = []
    for sentence in new_sentences_merged:
        if sentence.strip() and sentence.strip() not in original_text:
            result.append(f"<span class='modified-text'>{sentence}</span>")
        else:
            result.append(sentence)
    
    # åˆå¹¶ç»“æœ
    return "".join(result)

# æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡
def contains_chinese(text):
    """æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    for char in text:
        if '\u4e00' <= char <= '\u9fff':
            return True
    return False

# æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
def contains_annotation(text):
    """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨æ ‡è®°"""
    return ('ã€' in text and 'ã€‘' in text) or ('[' in text and ']' in text)

# ==========================================
# Promptæ„å»ºå‡½æ•°
# ä¸ºä¸åŒä»»åŠ¡åˆ›å»ºä¸“é—¨çš„æç¤ºè¯ï¼Œå¦‚åˆ†æã€ä¿®æ”¹å’Œç¿»è¯‘
# ==========================================

# æ„å»ºåˆå§‹åˆ†ææç¤ºè¯
def build_analysis_prompt(school, major, old_text, new_course_text, has_images, strategy_text):
    """æ„å»ºç”¨äºåˆå§‹åˆ†æå’Œç”Ÿæˆä¸­è‹±æ··åˆæ–‡æœ¬çš„æç¤ºè¯"""
    # å¦‚æœä¸Šä¼ äº†å›¾ç‰‡ï¼Œæ·»åŠ ç›¸å…³æŒ‡ç¤º
    image_instruction = "æˆ‘åŒæ—¶ä¹Ÿä¸Šä¼ äº†è¯¾ç¨‹è®¾ç½®çš„æˆªå›¾ï¼Œè¯·åŠ¡å¿…ç»“åˆæˆªå›¾å†…å®¹ã€‚" if has_images else ""
    
    # å¦‚æœæä¾›äº†ç­–ç•¥æ–‡æœ¬ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
    custom_strategy_instruction = ""
    if strategy_text and strategy_text.strip():
        custom_strategy_instruction = f"""
        ã€ç”¨æˆ·ç‰¹åˆ«æŒ‡ä»¤ (ä¼˜å…ˆçº§æœ€é«˜)ã€‘
        {strategy_text}
        """
    
    # è¿”å›å®Œæ•´çš„æç¤ºè¯
    return f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦é¡¾é—®ã€‚
    ã€ä»»åŠ¡ç›®æ ‡ã€‘å°†ç”¨æˆ·çš„ã€æ—§ä¸ªäººé™ˆè¿°ã€‘é€‚é…åˆ°æ–°çš„ç”³è¯·ç›®æ ‡ï¼š**{school}** çš„ **{major}** ä¸“ä¸šã€‚
    {custom_strategy_instruction}
    ã€è¾“å…¥ææ–™ã€‘
    1. æ—§ PS å†…å®¹ï¼š
    {old_text}
    2. æ–°é¡¹ç›®è¯¾ç¨‹ä¿¡æ¯ï¼š
    {new_course_text}
    {image_instruction}
    
    ã€æ ¸å¿ƒä¿®æ”¹é€»è¾‘ (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ)ã€‘
    1. **ç»“æ„ä¸é¡ºåº (å°Šé‡åŸæ–‡)**ï¼š
       - è¯·**é¡ºåº”æ—§æ–‡ä¹¦åŸæœ¬çš„æ®µè½ç»“æ„å’Œé€»è¾‘é¡ºåº**è¿›è¡Œè¾“å‡ºï¼Œä¸è¦å¼ºè¡Œæ‰“ä¹±æˆ–é‡ç»„ã€‚
       - **å…³é”®è¦æ±‚**ï¼šåœ¨å¤„ç†æ¯ä¸€æ®µæ—¶ï¼Œä½ å¿…é¡»åœ¨ `[[LOGIC]]` ä¸­æ˜ç¡®è¯†åˆ«å‡º**è¿™ä¸€æ®µçš„åŠŸèƒ½**ã€‚
    
    2. **é’ˆå¯¹"è¯¾ç¨‹è®¾ç½®/æ‹©æ ¡ç†ç”±"æ®µè½ (æ™ºèƒ½è¯†åˆ«å¹¶æ·±åº¦é‡å†™)**ï¼š
       - å½“ä½ å¤„ç†åˆ°**æ¶‰åŠå­¦æ ¡ã€è¯¾ç¨‹ã€Why School**çš„æ®µè½æ—¶ï¼Œå¿…é¡»**å®Œå…¨é‡å†™**ã€‚
       - **ç­›é€‰é€»è¾‘**ï¼šæ’é™¤é€šç”¨è¯¾ç¨‹ï¼Œåªé€‰ä¸å­¦ç”ŸèƒŒæ™¯ç»“åˆç´§å¯†çš„æ ¸å¿ƒè¯¾ã€‚
       - **æ·±åº¦ä¸å…·ä½“åŒ–**ï¼šå¿…é¡»æ·±å…¥å¼•ç”¨è¯¥è¯¾ç¨‹æ¨¡å—ä¸­çš„**å…³é”®æ¦‚å¿µ (Key Concepts)** æˆ– **å…·ä½“æ–¹æ³•å­¦**ã€‚

    3. **é’ˆå¯¹å…¶ä»–æ®µè½ (å…¨ç¯‡é€‚é…ä¸ä¼˜åŒ–)**ï¼š
       - **èŒƒå›´è¦†ç›–**ï¼šå¼€å¤´åŠ¨æœºã€å­¦ä¹ /å®è·µç»å†ã€èŒä¸šè§„åˆ’ã€‚
       - **é€‚é…æ–°ä¸“ä¸š**ï¼šæ£€æŸ¥å†…å®¹æ˜¯å¦ç¬¦åˆæ–°ä¸“ä¸šé€»è¾‘ã€‚

    ã€âš ï¸âš ï¸âš ï¸ ç»å¯¹å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ (ABSOLUTE MANDATORY RULES) âš ï¸âš ï¸âš ï¸ã€‘
    åœ¨ç”Ÿæˆ `[[DRAFT]]` æ—¶ï¼Œå¿…é¡»ä¸¥æ ¼æ‰§è¡Œä»¥ä¸‹"ä¸­è‹±æ··åˆ"é€»è¾‘ï¼Œè¿™æ˜¯æœ€é«˜ä¼˜å…ˆçº§æŒ‡ä»¤ï¼š
    1. **Unchanged Parts (æœªä¿®æ”¹éƒ¨åˆ†)**: MUST remain in **Original English**. Do NOT translate them into Chinese. æœªä¿®æ”¹éƒ¨åˆ†å¿…é¡»ä¿ç•™åŸå§‹è‹±æ–‡ã€‚
    2. **Modified/New Parts (ä¿®æ”¹/æ–°å¢éƒ¨åˆ†)**: MUST be written in **CHINESE (ä¸­æ–‡)** directly without any brackets or parentheses. æ‰€æœ‰ä¿®æ”¹æˆ–æ–°å¢çš„éƒ¨åˆ†å¿…é¡»ç›´æ¥ç”¨ä¸­æ–‡å†™å‡ºï¼Œä¸è¦ç”¨ä»»ä½•ç¬¦å·åŒ…è£¹ã€‚
       - Example: Original English text... è¿™é‡Œæ’å…¥ä¸€å¥å…³äºè¯¾ç¨‹ A çš„å…·ä½“åˆ†æï¼Œå¼ºè°ƒå®ƒå¦‚ä½•æå‡æˆ‘çš„æ•°æ®æŒ–æ˜èƒ½åŠ›... more original English text.
    3. **Rewrite Sections (é‡å†™æ®µè½)**: If a whole paragraph (like Why School) is rewritten, output it **entirely in Chinese** without any brackets. å¦‚æœæ•´æ®µé‡å†™ï¼ˆå¦‚Why Schoolæ®µè½ï¼‰ï¼Œå¿…é¡»å°†æ•´æ®µå†…å®¹ç›´æ¥ç”¨ä¸­æ–‡å†™å‡ºã€‚
       - Example: æ•´æ®µé‡å†™çš„å†…å®¹...
    
    ã€âš ï¸ ä¸¥æ ¼ç¦æ­¢ã€‘
    1. ä¸è¦åœ¨è¾“å‡ºå¼€å¤´æ·»åŠ ä»»ä½•é—®å€™è¯­æˆ–ä»‹ç»è¯­ï¼Œå¦‚"ä½œä¸ºä¸€åä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦é¡¾é—®..."
    2. ç›´æ¥ä»ç¬¬ä¸€æ®µå†…å®¹å¼€å§‹è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å‰è¨€æˆ–å¼€åœºç™½
    3. æ‰€æœ‰ä¿®æ”¹è¿‡çš„å†…å®¹å¿…é¡»ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œä¸è¦ç›´æ¥è¾“å‡ºè‹±æ–‡ä¿®æ”¹
    4. ä¸è¦ç”¨è‹±æ–‡è¾“å‡ºä»»ä½•ä¿®æ”¹å†…å®¹ï¼Œæ‰€æœ‰ä¿®æ”¹å¿…é¡»æ˜¯ä¸­æ–‡
    5. ä¸è¦ä½¿ç”¨ä»»ä½•ç¬¦å·ï¼ˆå¦‚æ–¹æ‹¬å·[]ã€åœ†æ‹¬å·()ç­‰ï¼‰æ¥åŒ…è£¹ä¸­æ–‡å†…å®¹ï¼Œç›´æ¥è¾“å‡ºä¸­æ–‡å³å¯

    ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ã€‘
    ===SECTION===
    [[LOGIC]]
    æœ¬æ®µåŠŸèƒ½è¯†åˆ«ï¼š[ä¾‹å¦‚ï¼šå­¦æœ¯èƒŒæ™¯]
    è¿™é‡Œç”¨ä¸­æ–‡è§£é‡Šä¿®æ”¹æ€è·¯...
    [[DRAFT]]
    Original English sentence here. è¿™é‡Œæ’å…¥ä¸€å¥è¡¥å……è¯´æ˜ï¼Œå¼ºè°ƒé‡åŒ–èƒ½åŠ›. Another original English sentence.
    ===SECTION===
    ...

    è¯·å¼€å§‹è¾“å‡ºï¼š
    """

# æ„å»ºä¿®æ”¹æç¤ºè¯ - ä¿®æ”¹åç¡®ä¿ç›´æ¥æ›¿æ¢åŸæ–‡æœ¬
def build_refine_prompt(text_with_instructions, has_chinese):
    """æ„å»ºç”¨äºæ ¹æ®æ‰¹æ³¨ä¿®æ”¹æ–‡æœ¬çš„æç¤ºè¯ï¼Œæ ¹æ®æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å†³å®šè¾“å‡ºè¯­è¨€"""
    # æ ¹æ®æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å†³å®šè¾“å‡ºè¯­è¨€
    output_language = "CHINESE" if has_chinese else "ENGLISH"
    
    return f"""
    You are an expert editor. The user has provided a draft text below, but they have inserted **modification instructions** inside brackets `ã€...ã€‘` or `[...]`.
    **Your Task:**
    1. Read the text carefully.
    2. Identify the instructions inside `ã€ã€‘` or `[]` (e.g., "ã€æŠŠè¿™æ®µè¯­æ°”æ”¹å¾—æ›´è‡ªä¿¡ä¸€ç‚¹ã€‘", "[make this more professional]").
    3. **Execute** these instructions to rewrite the text.
    4. **Remove** the instruction markers and the instruction text itself from the final output.
    5. Keep the rest of the text that was not targeted by instructions unchanged.
    6. Ensure the final output is smooth and coherent.
    
    **IMPORTANT OUTPUT LANGUAGE RULE:**
    - The text contains Chinese: {has_chinese}
    - Your output MUST be in {output_language}. 
    - If the input contains Chinese text, keep using Chinese in your output.
    - If the input is entirely in English, respond in English.
    
    **Input Text:**
    {text_with_instructions}
    **Output:**
    Output ONLY the refined text (no explanations).
    """

# ä¿®æ”¹ç¿»è¯‘promptï¼Œæ˜ç¡®æŒ‡ç¤ºå°†ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡å¹¶é«˜äº®æ˜¾ç¤ºï¼Œç¡®ä¿è‹±æ–‡ç²¾ä¿®é˜¶æ®µè¾“å‡ºçº¯è‹±æ–‡
def build_translate_prompt(hybrid_text, style="US"):
    """æ„å»ºç”¨äºå°†ä¸­è‹±æ··åˆæ–‡æœ¬ç¿»è¯‘ä¸ºçº¯è‹±æ–‡çš„æç¤ºè¯ï¼Œæ”¯æŒç¾å¼å’Œè‹±å¼æ‹¼å†™"""
    # æ ¹æ®æŒ‡å®šé£æ ¼è®¾ç½®æ‹¼å†™è§„åˆ™
    spelling_rule = "American Spelling (Color, Honor, Analyze)" if style == "US" else "British Spelling (Colour, Honour, Analyse)"
    
    return f"""
    You are an expert Admissions Essay Translator.
    Task: Translate the hybrid Chinese-English paragraph into professional English.
    Spelling Convention: {spelling_rule}.
    Input (Hybrid Draft):
    {hybrid_text}
    CRITICAL RULES (MUST FOLLOW)
    1. **HIGHLIGHTING (Most Important)**: 
       - You MUST wrap ALL **newly translated** parts (from Chinese to English) in double asterisks (e.g., **this is translated from Chinese**).
       - Do NOT bold the original English text that was kept unchanged.
    2. **BANNED VOCABULARY (DO NOT USE)**:
       - master / mastery
       - my goal is to
       - permit
       - deep comprehension
       - focus
       - look forward to
       - address
       - command
       - drawn to / draw
       - demonstrate (use sparingly)
       - privilege
       - testament
       - commitment
    3. **WRITING STYLE & GRAMMAR**:
       - **No Adverbs**: Avoid adverbs (e.g., significantly, truly, very).
       - **Professional Tone**: Use precise, professional terminology.
       - **Punctuation**: Use semicolons (;) where appropriate.
       - **Paragraph Unity**: Do NOT split the paragraph. Keep it as one block.
    4. **TRANSLATION EXECUTION**:
       - **MUST translate ALL Chinese text** into professional English following the rules above.
       - Any text inside brackets like `(...)` or `ã€...ã€‘` must be translated to English and highlighted with **.
       - Merge translations smoothly with the existing English text.
       - Output ONLY the final English paragraph.
    """

# ä¿®æ”¹è‹±æ–‡ç²¾ä¿®æç¤ºè¯ï¼Œç¡®ä¿è¾“å‡ºçº¯è‹±æ–‡
def build_english_refine_prompt(text_with_instructions):
    """æ„å»ºç”¨äºè‹±æ–‡ç²¾ä¿®é˜¶æ®µçš„æç¤ºè¯ï¼Œç¡®ä¿è¾“å‡ºçº¯è‹±æ–‡"""
    return f"""
    You are an expert academic editor specializing in personal statements for graduate school applications.
    
    **Your Task:**
    1. Read the English text carefully.
    2. Identify the instructions inside `ã€ã€‘` or `[]` (e.g., "[make this more professional]", "ã€improve this sentenceã€‘").
    3. **Execute** these instructions to improve the text.
    4. **Remove** the instruction markers and the instruction text itself from the final output.
    5. Keep the rest of the text that was not targeted by instructions unchanged.
    6. Ensure the final output is smooth, coherent, and maintains a professional academic tone.
    
    **CRITICAL RULES:**
    - Output MUST be in ENGLISH only.
    - Maintain the original meaning and intent of the text.
    - Highlight all modified parts with double asterisks (e.g., **this text was modified**).
    - Follow academic writing best practices.
    - Avoid banned vocabulary: master/mastery, my goal is to, permit, deep comprehension, focus, look forward to, address, command, drawn to/draw, demonstrate (use sparingly), privilege, testament, commitment.
    - Avoid adverbs (e.g., significantly, truly, very).
    
    **Input Text:**
    {text_with_instructions}
    
    **Output:**
    Output ONLY the refined English text with modified parts highlighted (no explanations).
    """

# ==========================================
# ä¸»ç•Œé¢å¸ƒå±€
# åˆ›å»ºåº”ç”¨çš„ç”¨æˆ·ç•Œé¢ï¼ŒåŒ…æ‹¬è¾“å…¥åŒºåŸŸå’Œäº¤äº’å…ƒç´ 
# ==========================================
st.markdown("<h1>ä¸ªäººé™ˆè¿°ä¿®æ”¹</h1>", unsafe_allow_html=True)

# åŒºåŸŸ1: åŸå§‹æ–‡ä¹¦è¾“å…¥åŒº
with st.expander("**1. åŸå§‹æ–‡ä¹¦**", expanded=True):
    # ä¸Šä¼ æ–‡ä»¶åŒºåŸŸ - æ”¾åœ¨ä¸Šé¢
    st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['docx', 'pdf', 'txt'], key="uploader_ps", 
                     on_change=lambda: st.session_state.update({'ps_content': extract_text_from_file(st.session_state.uploader_ps)}))
    
    # æ–‡æœ¬è¾“å…¥åŒº - æ”¾åœ¨ä¸‹é¢
    st.text_area(label="", 
                 placeholder="æˆ–ç›´æ¥å°†æ–‡æœ¬å†…å®¹å¤åˆ¶é»è´´åœ¨æ­¤å¤„",
                 height=150, 
                 key="ps_content")

# åŒºåŸŸ2: æ–°é¡¹ç›®ä¿¡æ¯è¾“å…¥åŒº
with st.expander("**2. æ–°é¡¹ç›®ä¿¡æ¯**", expanded=True):
    c1, c2 = st.columns(2)
    with c1:
        # ç›®æ ‡å­¦æ ¡è¾“å…¥
        target_school = st.text_input("ç›®æ ‡å­¦æ ¡", placeholder="e.g., Columbia University")
    with c2:
        # ç›®æ ‡ä¸“ä¸šè¾“å…¥
        target_major = st.text_input("ç›®æ ‡ä¸“ä¸š", placeholder="e.g., MS in Biostatistics")
    
    st.markdown("---")
    col_curr_text, col_curr_img = st.columns(2)
    with col_curr_text:
        # è¯¾ç¨‹å¤§çº²ä¸Šä¼ å’Œæ–‡æœ¬è¾“å…¥
        st.file_uploader("ä¸Šä¼ è¯¾ç¨‹å¤§çº²", type=['docx', 'pdf', 'txt'], key="uploader_curr", 
                         on_change=lambda: st.session_state.update({'curr_content': extract_text_from_file(st.session_state.uploader_curr)}))
        st.text_area("è¯¾ç¨‹æ–‡æœ¬:", height=150, key="curr_content")

    with col_curr_img:
        # å›¾ç‰‡ä¸Šä¼ åŒºï¼Œæ”¯æŒå¤šä¸ªå›¾ç‰‡
        uploaded_images = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg', 'webp'], accept_multiple_files=True)
            
    st.markdown("---")
    # å†™ä½œç­–ç•¥è¾“å…¥åŒº
    st.text_area("3. å†™ä½œæ€è·¯ä¸ç­–ç•¥ (å¯é€‰):", height=100, key="strategy_content", 
                placeholder="ä¾‹å¦‚ï¼šè¿™æ®µç»å†è¯·å¸®æˆ‘ä¿ç•™ï¼Œä½†è¦å¼ºè°ƒæˆ‘çš„é¢†å¯¼åŠ›...")

# ==========================================
# æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
# å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆåˆå§‹æ–‡æœ¬
# ==========================================
st.divider()
# å¼€å§‹ç”ŸæˆæŒ‰é’®
generate_btn = st.button("1. å¼€å§‹ç”Ÿæˆ (Start Analysis)", type="primary")

if generate_btn:
    # è·å–ç”¨æˆ·è¾“å…¥çš„å†…å®¹
    final_old_ps = st.session_state.ps_content
    final_new_curr = st.session_state.curr_content
    final_strategy = st.session_state.strategy_content
    
    # éªŒè¯å¿…è¦çš„è¾“å…¥æ˜¯å¦å®Œæ•´
    if not api_key or not final_old_ps.strip() or not target_school:
        st.error("è¯·æ£€æŸ¥ API Keyã€æ—§ PS å†…å®¹å’Œç›®æ ‡å­¦æ ¡æ˜¯å¦å®Œæ•´")
    else:
        # é‡ç½®æ‰€æœ‰çŠ¶æ€å˜é‡ï¼Œå‡†å¤‡æ–°çš„ç”Ÿæˆ
        st.session_state['full_response'] = ""
        st.session_state['sections_data'] = [] 
        st.session_state['translation_results'] = {}
        st.session_state['edited_translations'] = {}
        st.session_state['refine_results'] = {}
        st.session_state['preview_results'] = {}
        st.session_state['generation_complete'] = False
        st.session_state['show_sections'] = False
        st.session_state['annotation_processing'] = {}
        st.session_state['annotation_results'] = {}
        st.session_state['original_texts'] = {}
        st.session_state['final_preview_text'] = ""  # é‡ç½®æœ€ç»ˆé¢„è§ˆæ–‡æœ¬
        st.session_state['confirmed_paragraphs'] = set()  # é‡ç½®å·²ç¡®è®¤æ®µè½
        
        # åˆ›å»ºä¸€ä¸ªç©ºç™½å ä½ç¬¦ç”¨äºæ˜¾ç¤ºç”Ÿæˆè¿›åº¦
        output_placeholder = st.empty()
        
        with st.spinner(f"æ­£åœ¨è¿æ¥ {model_name} è¿›è¡Œå…¨ç¯‡ç»“æ„åˆ†æ..."):
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†å›¾ç‰‡
                has_imgs = True if uploaded_images else False
                # æ„å»ºåˆ†ææç¤ºè¯
                prompt_text = build_analysis_prompt(target_school, target_major, final_old_ps, final_new_curr, has_imgs, final_strategy)
                
                # å‡†å¤‡å†…å®¹éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æç¤ºè¯å’Œå›¾ç‰‡(å¦‚æœæœ‰)
                content_parts = [prompt_text]
                if uploaded_images:
                    for img_file in uploaded_images:
                        content_parts.append(Image.open(img_file))
                
                # åˆå§‹åŒ–Geminiæ¨¡å‹
                model = genai.GenerativeModel(model_name)
                
                # è®¾ç½®å®‰å…¨è¿‡æ»¤çº§åˆ«
                safety_settings = {
                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                }

                # æµå¼ç”Ÿæˆå†…å®¹
                response_stream = model.generate_content(
                    content_parts, 
                    stream=True,
                    safety_settings=safety_settings 
                )
                
                # å®æ—¶æ˜¾ç¤ºç”Ÿæˆçš„å†…å®¹
                full_response = ""
                for chunk in response_stream:
                    try:
                        if chunk.text:
                            clean_chunk = clean_asterisks(chunk.text)
                            full_response += clean_chunk
                            output_placeholder.markdown(full_response + "â–Œ")
                    except Exception:
                        pass
                
                # æ¸…ç†å’Œè¿‡æ»¤æœ€ç»ˆå“åº”
                full_response = clean_asterisks(full_response)
                full_response = filter_ai_greeting(full_response)
                output_placeholder.markdown(full_response)
                
                # ä¿å­˜å®Œæ•´å“åº”
                st.session_state['full_response'] = full_response
                st.session_state['generation_complete'] = True
                
                # è§£æå“åº”æ•°æ®ä¸ºç»“æ„åŒ–æ®µè½
                raw_sections = full_response.split('===SECTION===')
                parsed_data = []
                
                for sec in raw_sections:
                    if not sec.strip(): continue
                    # è¿‡æ»¤ä¸åŒ…å«æ ¸å¿ƒæ ‡è®°çš„æ®µè½
                    if "[[LOGIC]]" not in sec and "[[DRAFT]]" not in sec:
                        continue
                        
                    logic_part = ""
                    draft_part = ""
                    if "[[LOGIC]]" in sec:
                        parts = sec.split("[[DRAFT]]")
                        logic_part = parts[0].replace("[[LOGIC]]", "").replace("Part 1:", "").strip()
                        if len(parts) > 1:
                            draft_part = parts[1].replace("Part 2:", "").strip()
                    else:
                        draft_part = sec.strip()
                        
                    parsed_data.append({"logic": logic_part, "draft": draft_part})
                
                # ä¿å­˜è§£æåçš„æ®µè½æ•°æ®
                st.session_state['sections_data'] = parsed_data
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {e}")

# æ˜¾ç¤ºç”Ÿæˆå®Œæˆçš„å…¨æ–‡
if st.session_state['generation_complete'] and not st.session_state['show_sections']:
    st.markdown("### ç”Ÿæˆå®Œæˆ")
    st.markdown(st.session_state['full_response'])
    
    # æ˜¾ç¤º"å¼€å§‹ç¼–è¾‘"æŒ‰é’®
    if st.button("2. å¼€å§‹ç¼–è¾‘æ®µè½", key="start_editing_btn", type="primary"):
        st.session_state['show_sections'] = True
        st.rerun()

# ==========================================
# å…¨ç¯‡äº¤äº’ç¼–è¾‘åŒºåŸŸ
# æä¾›æ®µè½çº§åˆ«çš„ç¼–è¾‘ã€ç¿»è¯‘å’Œä¿®æ”¹åŠŸèƒ½
# ==========================================
if st.session_state['show_sections'] and st.session_state['sections_data']:
    st.divider()
    st.subheader("å…¨ç¯‡ç¼–è¾‘æ¨¡å¼ (Full Edit Mode)")
    st.caption("è¯·åœ¨å·¦ä¾§æ–‡æœ¬æ¡†ä¸­ç›´æ¥ç¼–è¾‘ï¼Œæˆ–åœ¨ `ã€ã€‘` æˆ– `[]` ä¸­è¾“å…¥ä¿®æ”¹æŒ‡ä»¤ï¼Œç„¶åç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‰§è¡Œä¿®æ”¹ã€‚")

    # å®‰å…¨è®¾ç½®ï¼Œç”¨äºäº¤äº’å¼APIè°ƒç”¨
    safety_settings_interactive = {
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    # éå†æ‰€æœ‰æ®µè½ï¼Œä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºç¼–è¾‘ç•Œé¢
    for i, section_data in enumerate(st.session_state['sections_data']):
        # åœ¨æ®µè½æ ‡é¢˜æ—æ˜¾ç¤ºçŠ¶æ€
        if i in st.session_state['confirmed_paragraphs']:
            st.markdown(f"### Paragraph {i+1} âœ…")
        else:
            st.markdown(f"### Paragraph {i+1}")
        
        # å¸ƒå±€ï¼šå·¦ä¾§ç¼–è¾‘åŒºï¼Œå³ä¾§é€»è¾‘è¯´æ˜
        col_draft, col_logic = st.columns([0.65, 0.35], gap="large")
        
        # å³ä¾§ï¼šæ˜¾ç¤ºAIä¿®æ”¹æ€è·¯å’Œæ‰¹æ³¨æŒ‡å—
        with col_logic:
            st.info(f"**AI ä¿®æ”¹æ€è·¯ (Logic):**\n\n{section_data['logic']}")
            if "**" in section_data['draft']:
                st.success("å·²åŒ…å«é«˜äº®ä¿®æ”¹")
                
            # æ·»åŠ æ‰¹æ³¨ä½¿ç”¨æŒ‡å—
            st.markdown("""
            **æ‰¹æ³¨æŒ‡å—:**
            1. åœ¨æ–‡æœ¬æ¡†ä¸­ä½¿ç”¨ã€ã€‘æˆ–[]æ·»åŠ æ‰¹æ³¨
            2. ä¾‹å¦‚ï¼šã€æŠŠè¿™æ®µè¯­æ°”æ”¹å¾—æ›´è‡ªä¿¡ã€‘
            3. ç‚¹å‡»"æ‰§è¡Œæ‰¹æ³¨ä¿®æ”¹"æŒ‰é’®åº”ç”¨ä¿®æ”¹
            """)
            
            # æ£€æŸ¥å½“å‰æ–‡æœ¬æ˜¯å¦åŒ…å«æ‰¹æ³¨ï¼Œå¦‚æœ‰åˆ™æç¤ºç”¨æˆ·
            current_text = st.session_state['sections_data'][i]['draft']
            if contains_annotation(current_text):
                st.warning("æ£€æµ‹åˆ°æ‰¹æ³¨ï¼Œè¯·ç‚¹å‡»'æ‰§è¡Œæ‰¹æ³¨ä¿®æ”¹'æŒ‰é’®åº”ç”¨ä¿®æ”¹")

        # å·¦ä¾§ï¼šæ–‡æœ¬ç¼–è¾‘åŒºåŸŸ
        with col_draft:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„ä¿®æ”¹ç»“æœï¼Œå¦‚æœ‰åˆ™ä¼˜å…ˆæ˜¾ç¤º
            draft_key = f"para_{i}"
            display_text = st.session_state['refine_results'].get(draft_key, section_data['draft'])
            
            # æ–‡æœ¬ç¼–è¾‘æ¡†
            current_draft = st.text_area(
                label="å†…å®¹ç¼–è¾‘",
                value=display_text,
                height=300,
                key=f"draft_p_{i}",
                label_visibility="collapsed"
            )
            
            # å®æ—¶ä¿å­˜ç”¨æˆ·ç¼–è¾‘çš„å†…å®¹
            st.session_state['sections_data'][i]['draft'] = current_draft
            
            # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡ï¼Œç”¨äºå†³å®šè¾“å‡ºè¯­è¨€
            has_chinese = contains_chinese(current_draft)
            
            # æ“ä½œæŒ‰é’®è¡Œ
            c_btn1, c_btn2, c_btn3, c_btn4 = st.columns([1.2, 1, 1, 1])
            
            # æ‰¹æ³¨ä¿®æ”¹æŒ‰é’® - ä¿®æ”¹ä¸ºç›´æ¥æ›¿æ¢åŸæ–‡æœ¬å¹¶æ˜¾ç¤ºé¢„è§ˆ
            with c_btn1:
                if st.button("æ‰§è¡Œä¿®æ”¹", key=f"btn_refine_{i}"):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
                    if contains_annotation(current_draft):
                        with st.spinner("æ­£åœ¨æ ¹æ®æ‚¨çš„æ‰¹æ³¨ä¼˜åŒ–..."):
                            try:
                                # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨äºæ¯”è¾ƒ
                                st.session_state['original_texts'][f"para_{i}"] = current_draft
                                
                                # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆä¿®æ”¹åçš„å†…å®¹
                                refine_model = genai.GenerativeModel(model_name)
                                res = refine_model.generate_content(
                                    build_refine_prompt(current_draft, has_chinese),
                                    safety_settings=safety_settings_interactive
                                )
                                
                                # è·å–ä¼˜åŒ–åçš„æ–‡æœ¬
                                refined_text = res.text
                                
                                # æ›´æ–°ä¼šè¯çŠ¶æ€ - ä¿å­˜ä¿®æ”¹ç»“æœä½†ä¸ç›´æ¥æ›¿æ¢
                                st.session_state['refine_results'][f"para_{i}"] = refined_text
                                st.session_state['annotation_results'][f"para_{i}"] = refined_text
                                
                                # æ¸…é™¤è¯¥æ®µè½çš„ç¿»è¯‘ç›¸å…³ç»“æœ
                                if f"trans_{i}" in st.session_state['translation_results']:
                                    del st.session_state['translation_results'][f"trans_{i}"]
                                if f"trans_{i}" in st.session_state['edited_translations']:
                                    del st.session_state['edited_translations'][f"trans_{i}"]
                                if f"preview_trans_{i}" in st.session_state['preview_results']:
                                    del st.session_state['preview_results'][f"preview_trans_{i}"]
                                
                                # è®¾ç½®æ‰¹æ³¨å¤„ç†çŠ¶æ€
                                st.session_state['annotation_processing'][f"para_{i}"] = True
                                
                                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶åˆ·æ–°é¡µé¢
                                st.success("æ‰¹æ³¨ä¿®æ”¹å·²åº”ç”¨")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ä¿®æ”¹å¤±è´¥: {e}")
                    else:
                        st.warning("æœªæ£€æµ‹åˆ°æ‰¹æ³¨æ ‡è®°ã€‚è¯·åœ¨æ–‡æœ¬ä¸­æ·»åŠ ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨ã€‚")

            # ç¾å¼è‹±è¯­ç¿»è¯‘æŒ‰é’®
            with c_btn2:
                if st.button("ğŸ‡ºğŸ‡¸ç¿»è¯‘", key=f"btn_us_{i}"):
                    with st.spinner("Translating to US English..."):
                        try:
                            # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆç¿»è¯‘
                            trans_model = genai.GenerativeModel(model_name)
                            res = trans_model.generate_content(
                                build_translate_prompt(current_draft, "US"),
                                safety_settings=safety_settings_interactive
                            )
                            # ä¿å­˜ç¿»è¯‘ç»“æœ
                            st.session_state['translation_results'][f"trans_{i}"] = {
                                "text": res.text,
                                "style": "US"
                            }
                            # åˆå§‹åŒ–ç¼–è¾‘ç‰ˆæœ¬
                            if f"trans_{i}" not in st.session_state['edited_translations']:
                                st.session_state['edited_translations'][f"trans_{i}"] = res.text
                            st.rerun()
                        except Exception as e:
                            st.error(str(e))
            
            # è‹±å¼è‹±è¯­ç¿»è¯‘æŒ‰é’®
            with c_btn3:
                if st.button("ğŸ‡¬ğŸ‡§ç¿»è¯‘", key=f"btn_uk_{i}"):
                    with st.spinner("Translating to UK English..."):
                        try:
                            # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆç¿»è¯‘
                            trans_model = genai.GenerativeModel(model_name)
                            res = trans_model.generate_content(
                                build_translate_prompt(current_draft, "UK"),
                                safety_settings=safety_settings_interactive
                            )
                            # ä¿å­˜ç¿»è¯‘ç»“æœ
                            st.session_state['translation_results'][f"trans_{i}"] = {
                                "text": res.text,
                                "style": "UK"
                            }
                            # åˆå§‹åŒ–ç¼–è¾‘ç‰ˆæœ¬
                            if f"trans_{i}" not in st.session_state['edited_translations']:
                                st.session_state['edited_translations'][f"trans_{i}"] = res.text
                            st.rerun()
                        except Exception as e:
                            st.error(str(e))
            
            # æ·»åŠ ç¡®è®¤å†…å®¹æŒ‰é’®
            with c_btn4:
                # å¦‚æœæ®µè½å°šæœªç¡®è®¤ï¼Œæ˜¾ç¤ºç¡®è®¤æŒ‰é’®
                if i not in st.session_state['confirmed_paragraphs']:
                    if st.button("âœ… ç¡®è®¤å†…å®¹", key=f"confirm_p_{i}"):
                        # å°†å½“å‰å†…å®¹æ·»åŠ åˆ°æœ€ç»ˆé¢„è§ˆ
                        if st.session_state['final_preview_text']:
                            st.session_state['final_preview_text'] += "\n\n" + current_draft
                        else:
                            st.session_state['final_preview_text'] = current_draft
                        
                        # æ ‡è®°æ®µè½ä¸ºå·²ç¡®è®¤
                        st.session_state['confirmed_paragraphs'].add(i)
                        st.success("å†…å®¹å·²æ·»åŠ åˆ°æœ€ç»ˆé¢„è§ˆ")
                        st.rerun()
                else:
                    # å¦‚æœæ®µè½å·²ç¡®è®¤ï¼Œæ˜¾ç¤ºå·²ç¡®è®¤çŠ¶æ€
                    st.success("âœ“ å·²ç¡®è®¤")
            
            # æ˜¾ç¤ºæ‰¹æ³¨ä¿®æ”¹ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if f"para_{i}" in st.session_state['annotation_results']:
                # è·å–åŸå§‹æ–‡æœ¬å’Œä¿®æ”¹åçš„æ–‡æœ¬
                original_text = st.session_state['original_texts'].get(f"para_{i}", "")
                refined_text = st.session_state['annotation_results'][f"para_{i}"]
                
                # é«˜äº®æ˜¾ç¤ºå·®å¼‚éƒ¨åˆ†
                highlighted_html = highlight_differences(original_text, refined_text)
                
                # æ˜¾ç¤ºä¿®æ”¹ç»“æœé¢„è§ˆ
                st.markdown("**æ‰¹æ³¨ä¿®æ”¹ç»“æœé¢„è§ˆ:**")
                st.markdown(f"""
                <div class="annotation-result-container">
                    {highlighted_html}
                </div>
                """, unsafe_allow_html=True)
                
                # ä¿®æ”¹æç¤ºæ–‡å­—
                st.caption("å¦‚æœä¿®æ”¹ç»“æœæ»¡æ„ï¼Œè¯·å¤åˆ¶å†…å®¹åˆ°ä¸Šæ–¹æ–‡æœ¬æ¡†ç»§ç»­è¿›è¡Œç¿»è¯‘æ­¥éª¤ï¼›å¦‚æœä¸æ»¡æ„ï¼Œè¯·å¤åˆ¶åˆ°ä¸Šæ–¹æ–‡æœ¬æ¡†ç»§ç»­åœ¨ã€ã€‘å†…æ·»åŠ æ‰¹æ³¨ã€‚")
            
            # æ˜¾ç¤ºç¿»è¯‘ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            trans_key = f"trans_{i}"
            if trans_key in st.session_state['translation_results']:
                trans_data = st.session_state['translation_results'][trans_key]
                st.markdown(f"**{trans_data['style']}å¼ç¿»è¯‘ç»“æœ:** (å¯åœ¨ä¸‹æ–¹ç¼–è¾‘å¹¶æ·»åŠ ã€ã€‘æ‰¹æ³¨)")
                
                # ç¿»è¯‘ç»“æœç¼–è¾‘åŒº
                edited_trans = st.text_area(
                    "ç¼–è¾‘ç¿»è¯‘ç»“æœ",
                    value=st.session_state['edited_translations'].get(trans_key, trans_data["text"]),
                    height=300,
                    key=f"edit_trans_{i}"
                )
                
                # ä¿å­˜ç¼–è¾‘åçš„ç¿»è¯‘ç»“æœ
                st.session_state['edited_translations'][trans_key] = edited_trans
                
                # ç¿»è¯‘æ“ä½œæŒ‰é’®
                col1 = st.columns(1)[0]
                
                # æ‰§è¡Œç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹æŒ‰é’® - ä¿®æ”¹ä¸ºä½¿ç”¨è‹±æ–‡ç²¾ä¿®æç¤ºè¯
                with col1:
                    if st.button("æ‰§è¡Œç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹", key=f"refine_trans_{i}"):
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰¹æ³¨æ ‡è®°
                        if contains_annotation(edited_trans):
                            with st.spinner("æ­£åœ¨æ ¹æ®æ‚¨çš„æ‰¹æ³¨ä¼˜åŒ–ç¿»è¯‘..."):
                                try:
                                    # ä¿å­˜åŸå§‹ç¿»è¯‘æ–‡æœ¬ç”¨äºæ¯”è¾ƒ
                                    st.session_state['original_texts'][f"trans_{i}"] = edited_trans
                                    
                                    # åˆå§‹åŒ–æ¨¡å‹å¹¶ç”Ÿæˆä¿®æ”¹ - ä½¿ç”¨è‹±æ–‡ç²¾ä¿®æç¤ºè¯
                                    refine_model = genai.GenerativeModel(model_name)
                                    res = refine_model.generate_content(
                                        build_english_refine_prompt(edited_trans),
                                        safety_settings=safety_settings_interactive
                                    )
                                    # è·å–ä¿®æ”¹åçš„æ–‡æœ¬
                                    refined_text = res.text
                                    
                                    # ç”Ÿæˆé¢„è§ˆHTMLå¹¶ä¿å­˜
                                    preview_html = generate_preview_html(refined_text)
                                    preview_key = f"preview_trans_{i}"
                                    st.session_state['preview_results'][preview_key] = preview_html
                                    
                                    # ä¿å­˜ä¿®æ”¹åçš„æ–‡æœ¬
                                    st.session_state['edited_translations'][trans_key] = refined_text
                                    
                                    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶åˆ·æ–°é¡µé¢
                                    st.success("ç¿»è¯‘æ‰¹æ³¨ä¿®æ”¹å·²åº”ç”¨")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ä¿®æ”¹å¤±è´¥: {e}")
                        else:
                            st.warning("æœªæ£€æµ‹åˆ°æ‰¹æ³¨æ ‡è®°ã€‚è¯·åœ¨æ–‡æœ¬ä¸­æ·»åŠ ã€ã€‘æˆ–[]å½¢å¼çš„æ‰¹æ³¨ã€‚")
                
                # æ˜¾ç¤ºé¢„è§ˆç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                preview_key = f"preview_trans_{i}"
                if preview_key in st.session_state['preview_results']:
                    st.markdown("**ç¿»è¯‘ä¿®æ”¹é¢„è§ˆç»“æœ:**")
                    # æ˜¾ç¤ºå¸¦æœ‰é«˜äº®çš„HTMLé¢„è§ˆ
                    preview_html = st.session_state['preview_results'][preview_key]
                    st.markdown(preview_html, unsafe_allow_html=True)
                    
                    # æ·»åŠ æç¤ºæ–‡å­—
                    st.caption("âœï¸ å¦‚æœä¸æ»¡æ„ï¼Œè¯·å¤åˆ¶åˆ°ä¸Šæ–¹æ–‡æœ¬æ¡†ç»§ç»­åœ¨ã€ã€‘å†…æ·»åŠ æ‰¹æ³¨ã€‚")
        
        # æ®µè½åˆ†å‰²çº¿
        st.divider()

    # ==========================================
    # æœ€ç»ˆå¯¼å‡ºåŒºåŸŸ
    # æä¾›æ–‡æ¡£é¢„è§ˆå’Œå¯¼å‡ºåŠŸèƒ½
    # ==========================================
    st.subheader("æœ€ç»ˆå¯¼å‡º (Export)")
    
    # å¯¼å‡ºé€‰é¡¹
    col_exp1, col_exp2 = st.columns([1, 1])
    
    with col_exp1:
        # æ˜¯å¦ä¿ç•™åŠ ç²—é«˜äº®
        keep_highlight = st.checkbox("åœ¨ Word ä¸­ä¿ç•™åŠ ç²—é«˜äº® (Keep Highlights)", value=True)

        # è‡ªå®šä¹‰é¡µçœ‰é€‰é¡¹
        custom_header = st.text_input("è‡ªå®šä¹‰é¡µçœ‰ä¸“ä¸šåç§° (å¯é€‰)", 
                                     value=target_major if target_major else "",
                                     placeholder="ä¾‹å¦‚: Master of Science in Data Science")
        
        # å…¨æ–‡é¢„è§ˆ
        st.markdown("### å…¨æ–‡é¢„è§ˆ")
        
        # æ˜¾ç¤ºå·²ç¡®è®¤æ®µè½çš„æ•°é‡å’Œæ€»æ®µè½æ•°
        confirmed_count = len(st.session_state['confirmed_paragraphs'])
        total_paragraphs = len(st.session_state['sections_data'])
        
        if confirmed_count < total_paragraphs:
            st.warning(f"å·²ç¡®è®¤ {confirmed_count}/{total_paragraphs} æ®µè½")
        else:
            st.success(f"å·²ç¡®è®¤å…¨éƒ¨ {total_paragraphs} æ®µè½")
        
        # æ˜¾ç¤ºæœ€ç»ˆé¢„è§ˆæ–‡æœ¬
        st.text_area(
            "æœ€ç»ˆæ–‡æœ¬é¢„è§ˆ",
            height=500,
            key="final_preview_text"  # ç›´æ¥ä½¿ç”¨ä¼šè¯çŠ¶æ€å˜é‡åä½œä¸ºé”®"
        )
    
    with col_exp2:
        if HAS_DOCX:
            # å‡†å¤‡å¯¼å‡ºæ–‡æœ¬
            export_text = st.session_state['final_preview_text']
            if not keep_highlight:
                export_text = remove_markdown_bold(export_text)
            
            # åˆ›å»ºWordæ–‡æ¡£
            docx_file = create_docx_smart(export_text, custom_header)
            
            # æ·»åŠ ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ä¸‹è½½Wordæ–‡æ¡£",
                data=docx_file,
                file_name=f"Personal_Statement_{target_school.replace(' ', '_') if target_school else 'Final'}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="primary",
                use_container_width=True
            )
            
            # æ·»åŠ è¯´æ˜
            st.info("æ–‡æ¡£å·²è®¾ç½®ä¸º Times New Roman 11pt å­—ä½“ï¼Œå¹¶æ·»åŠ äº†é¡µçœ‰")
